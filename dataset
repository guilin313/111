# cremi_dataset.py
import h5py
import torch
import numpy as np
from torch.utils.data import Dataset

class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 crop_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.crop_size = crop_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.volume_shape = self.raw.shape  # (D, H, W)
        self.starts = self.compute_sliding_window_starts(self.volume_shape, self.crop_size)

    def compute_sliding_window_starts(self, volume_shape, crop_size):
        starts = []
        for size, patch in zip(volume_shape, crop_size):
            pos = list(range(0, size - patch + 1, patch))
            if (size - patch) % patch != 0:
                pos.append(size - patch)
            starts.append(pos)
        return [(z, y, x) for z in starts[0] for y in starts[1] for x in starts[2]]

    def __len__(self):
        return len(self.starts)

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        z, y, x = self.starts[idx]
        dz, dy, dx = self.crop_size

        raw_crop = self.raw[z:z+dz, y:y+dy, x:x+dx].astype(np.float32)
        label_crop = self.labels[z:z+dz, y:y+dy, x:x+dx].astype(np.int64)

        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor

if __name__ == "__main__":
    import numpy as np

    H5_PATH = "./segementation_data/sample_C_20160501.hdf"  # â† ä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„

    # å¤šç§ patch size é…ç½®
    PATCH_SIZES = [
        (32, 320, 320),
        (32, 160, 160),
        (32, 96, 96),
        (32, 64, 64),
        (64, 160, 160)
    ]

    max_patches = 50  # æ¯ç§ patch size åªç»Ÿè®¡å‰ N ä¸ª patch

    print(f"ğŸ“Š æ¯”è¾ƒå¤šç§ patch size ä¸‹çš„äº²å’Œå›¾è¿æ¥æ¯”ä¾‹ (sample_C_20160501.hdf, æ¯ç§å‰ {max_patches} ä¸ª patch)...\n")

    for patch_size in PATCH_SIZES:
        dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=patch_size)

        total_voxels = np.zeros(3, dtype=np.int64)
        total_ones = np.zeros(3, dtype=np.int64)

        N = min(max_patches, len(dataset))
        for i in range(N):
            _, aff = dataset[i]
            aff_np = aff.numpy()
            total_voxels += aff_np.shape[1] * aff_np.shape[2] * aff_np.shape[3]
            total_ones += aff_np.sum(axis=(1, 2, 3)).astype(np.int64)

        print(f"ğŸ§© Patch size: {patch_size}")
        directions = ['z+', 'y+', 'x+']
        for i in range(3):
            ratio = total_ones[i] / total_voxels[i]
            print(f"  âœ æ–¹å‘ {directions[i]}: è¿æ¥æ¯”ä¾‹ = {ratio:.4f} ({total_ones[i]}/{total_voxels[i]})")
        print("-" * 60)




if __name__ == "__main__":
    import numpy as np

    H5_PATH = "./segementation_data/sample_C_20160501.hdf"  # â† ä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„

    # å¤šç§ patch size é…ç½®
    PATCH_SIZES = [
        (32, 320, 320),
        (32, 160, 160),
        (32, 96, 96),
        (32, 64, 64),
        (64, 160, 160)
    ]

    max_patches = 50  # æ¯ç§ patch size åªç»Ÿè®¡å‰ N ä¸ª patch

    print(f"ğŸ“Š æ¯”è¾ƒå¤šç§ patch size ä¸‹çš„äº²å’Œå›¾è¿æ¥æ¯”ä¾‹ (sample_C_20160501.hdf, æ¯ç§å‰ {max_patches} ä¸ª patch)...\n")

    for patch_size in PATCH_SIZES:
        dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=patch_size)

        total_voxels = np.zeros(3, dtype=np.int64)
        total_ones = np.zeros(3, dtype=np.int64)

        N = min(max_patches, len(dataset))
        for i in range(N):
            _, aff = dataset[i]
            aff_np = aff.numpy()
            total_voxels += aff_np.shape[1] * aff_np.shape[2] * aff_np.shape[3]
            total_ones += aff_np.sum(axis=(1, 2, 3)).astype(np.int64)

        print(f"ğŸ§© Patch size: {patch_size}")
        directions = ['z+', 'y+', 'x+']
        for i in range(3):
            ratio = total_ones[i] / total_voxels[i]
            print(f"  âœ æ–¹å‘ {directions[i]}: è¿æ¥æ¯”ä¾‹ = {ratio:.4f} ({total_ones[i]}/{total_voxels[i]})")
        print("-" * 60)


if __name__ == "__main__":
    import numpy as np

    H5_PATH = "./segementation_data/sample_C_20160501.hdf"  # â† è¯·æ ¹æ®ä½ å®é™…è·¯å¾„è°ƒæ•´
    CROP_SIZE = (32, 320, 320)

    dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)

    total_voxels = np.zeros(3, dtype=np.int64)
    total_ones = np.zeros(3, dtype=np.int64)

    N = min(100, len(dataset))  # æ£€æŸ¥å‰100ä¸ªpatchè¶³å¤Ÿä»£è¡¨æ€§
    print(f"ğŸ“Š æ­£åœ¨ç»Ÿè®¡ sample_C_20160501.hdf ä¸­å‰ {N} ä¸ª patch çš„äº²å’Œå›¾è¿æ¥æ¯”ä¾‹...")

    for i in range(N):
        _, aff = dataset[i]  # aff: [3, D, H, W]
        aff_np = aff.numpy()
        total_voxels += aff_np.shape[1] * aff_np.shape[2] * aff_np.shape[3]
        total_ones += aff_np.sum(axis=(1, 2, 3)).astype(np.int64)

    directions = ['z+', 'y+', 'x+']
    for i in range(3):
        ratio = total_ones[i] / total_voxels[i]
        print(f"â¡ï¸ æ–¹å‘ {directions[i]}: è¿æ¥æ¯”ä¾‹ = {ratio:.4f} ({total_ones[i]}/{total_voxels[i]})")



# cremi_affinity_3d_dataset.py
import h5py
import torch
import numpy as np
from torch.utils.data import Dataset

class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 patch_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.patch_size = patch_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.volume_shape = self.raw.shape  # (D, H, W)
        self.starts = self.compute_sliding_window_starts(self.volume_shape, self.patch_size)

    def compute_sliding_window_starts(self, volume_shape, patch_size):
        starts = []
        for size, patch in zip(volume_shape, patch_size):
            pos = list(range(0, size - patch + 1, patch))
            if (size - patch) % patch != 0:
                pos.append(size - patch)
            starts.append(pos)
        return [(z, y, x) for z in starts[0] for y in starts[1] for x in starts[2]]

    def __len__(self):
        return len(self.starts)

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        z, y, x = self.starts[idx]
        dz, dy, dx = self.patch_size

        raw_crop = self.raw[z:z+dz, y:y+dy, x:x+dx].astype(np.float32)
        label_crop = self.labels[z:z+dz, y:y+dy, x:x+dx].astype(np.int64)

        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor





# cremi_affinity_3d_dataset.py
import h5py
import torch
import numpy as np
from torch.utils.data import Dataset
import random

class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 crop_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.crop_size = crop_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.D, self.H, self.W = self.raw.shape

    def __len__(self):
        return 10000  # number of random crops per epoch

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        zd, yh, xw = self.crop_size  # âœ… ç¡®ä¿ä½¿ç”¨ä¼ å…¥ crop_size
        assert zd <= self.D and yh <= self.H and xw <= self.W, "Crop size must fit inside the volume"

        z = random.randint(0, self.D - zd)
        y = random.randint(0, self.H - yh)
        x = random.randint(0, self.W - xw)

        raw_crop = self.raw[z:z+zd, y:y+yh, x:x+xw].astype(np.float32)
        label_crop = self.labels[z:z+zd, y:y+yh, x:x+xw].astype(np.int64)

        assert raw_crop.shape == self.crop_size, f"Crop shape mismatch: got {raw_crop.shape}, expected {self.crop_size}"

        # å½’ä¸€åŒ– + æ ‡å‡†åŒ–
        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor
class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 crop_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.crop_size = crop_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.D, self.H, self.W = self.raw.shape

    def __len__(self):
        return 10000  # number of random crops per epoch

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        zd, yh, xw = self.crop_size
        z = random.randint(0, self.D - zd)
        y = random.randint(0, self.H - yh)
        x = random.randint(0, self.W - xw)

        raw_crop = self.raw[z:z+zd, y:y+yh, x:x+xw].astype(np.float32)
        #print("crop shape:", raw_crop.shape)
        label_crop = self.labels[z:z+zd, y:y+yh, x:x+xw].astype(np.int64)

        # å½’ä¸€åŒ– + æ ‡å‡†åŒ–
        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor



writer = SummaryWriter(log_dir=os.path.join(training_args.output_dir, "tb_samples"))
    log_dataset_samples(train_dataset, writer, tag_prefix="train", num_samples=5)
    log_dataset_samples(val_dataset, writer, tag_prefix="val", num_samples=3)
    writer.close()
    logger.info("âœ… Wrote sample slices to TensorBoard.")

def log_dataset_samples(dataset, writer, tag_prefix="train", num_samples=5):
    for idx in range(min(num_samples, len(dataset))):
        data = dataset[idx]["pixel_values"]  # shape: [1, D, H, W]
        image = data[0, data.shape[1] // 2]   # å–ä¸­é—´å±‚ [H, W]
        writer.add_image(f"{tag_prefix}_slice_{idx}", image.unsqueeze(0), global_step=0)



import os
import shutil
import random

# è®¾ç½®è·¯å¾„
src_dir = 'path/to/your/tif_images'  # åŸå§‹æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå­˜æ”¾æ‰€æœ‰ .tif å›¾åƒ
train_dir = 'path/to/save/train'  # å­˜å‚¨è®­ç»ƒé›†çš„æ–‡ä»¶å¤¹
val_dir = 'path/to/save/val'  # å­˜å‚¨éªŒè¯é›†çš„æ–‡ä»¶å¤¹

# åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç›®å½•
os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

# è·å–æ‰€æœ‰ .tif æ–‡ä»¶
tif_files = [f for f in os.listdir(src_dir) if f.endswith('.tif')]

# æ‰“ä¹±æ–‡ä»¶é¡ºåº
random.shuffle(tif_files)

# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
split_ratio = 0.9
train_size = int(len(tif_files) * split_ratio)

train_files = tif_files[:train_size]
val_files = tif_files[train_size:]

# å¤åˆ¶è®­ç»ƒé›†æ–‡ä»¶
for file in train_files:
    src_path = os.path.join(src_dir, file)
    dst_path = os.path.join(train_dir, file)
    shutil.copy(src_path, dst_path)

# å¤åˆ¶éªŒè¯é›†æ–‡ä»¶
for file in val_files:
    src_path = os.path.join(src_dir, file)
    dst_path = os.path.join(val_dir, file)
    shutil.copy(src_path, dst_path)

print(f"è®­ç»ƒé›†åŒ…å« {len(train_files)} å¼ å›¾ç‰‡")
print(f"éªŒè¯é›†åŒ…å« {len(val_files)} å¼ å›¾ç‰‡")





import os
import torch
import random
import numpy as np
import tifffile as tiff
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader

class TIFDataset(Dataset):
    def __init__(self, data_dir, augment=True):
        self.data_dir = data_dir
        self.file_list = sorted(os.listdir(data_dir))
        self.augment = augment

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        file_path = os.path.join(self.data_dir, self.file_list[idx])
        image = tiff.imread(file_path)  # (D, H, W)
        
        # å½’ä¸€åŒ–åˆ° [0,1]
        image = image.astype('float32') / 255.0  

        # 3D é¢„å¤„ç†
        image = self.preprocess(image)

        # è½¬æ¢ä¸º Tensor
        image = torch.tensor(image).unsqueeze(0)  # [C=1, D, H, W]
        return image

    def preprocess(self, image):
        """ æ•°æ®é¢„å¤„ç†ï¼šæ ‡å‡†åŒ– & æ•°æ®å¢å¼º """
        # æ ‡å‡†åŒ–ï¼ˆå‡å‡å€¼ï¼Œé™¤ä»¥æ ‡å‡†å·®ï¼‰
        image = (image - np.mean(image)) / (np.std(image) + 1e-5)

        if self.augment:
            image = self.augment_data(image)
        
        return image

    def augment_data(self, image):
        """ æ•°æ®å¢å¼ºï¼šéšæœºç¿»è½¬ã€æ—‹è½¬ã€é«˜æ–¯å™ªå£° """
        if random.random() > 0.5:
            image = np.flip(image, axis=1)  # å·¦å³ç¿»è½¬
        if random.random() > 0.5:
            image = np.flip(image, axis=2)  # ä¸Šä¸‹ç¿»è½¬
        if random.random() > 0.5:
            image = np.flip(image, axis=0)  # æ·±åº¦ç¿»è½¬

        # æ—‹è½¬ 90/180/270 åº¦
        if random.random() > 0.5:
            k = random.choice([1, 2, 3])
            image = np.rot90(image, k=k, axes=(1, 2))  

        # æ·»åŠ é«˜æ–¯å™ªå£°
        if random.random() > 0.7:
            noise = np.random.normal(0, 0.01, image.shape)
            image = np.clip(image + noise, 0, 1)

        return image

def get_dataloader(data_dir, batch_size=4, augment=True):
    dataset = TIFDataset(data_dir, augment=augment)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)


import os
import zipfile
import tarfile
import gzip
import shutil

def extract_archive(archive_path, output_dir):
    try:
        if archive_path.endswith(".zip"):
            with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                zip_ref.extractall(output_dir)
        elif archive_path.endswith((".tar.gz", ".tgz", ".tar")):
            with tarfile.open(archive_path, 'r:*') as tar_ref:
                tar_ref.extractall(output_dir)
        elif archive_path.endswith(".gz") and not archive_path.endswith(".tar.gz"):
            with gzip.open(archive_path, 'rb') as f_in:
                out_path = os.path.join(output_dir, os.path.basename(archive_path)[:-3])
                with open(out_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
        else:
            print(f"Unsupported format: {archive_path}")
    except Exception as e:
        print(f"âŒ Failed to extract {archive_path}: {e}")

def extract_all_in_dir(target_dir):
    for fname in os.listdir(target_dir):
        fpath = os.path.join(target_dir, fname)
        if not os.path.isfile(fpath):
            continue

        name, ext = os.path.splitext(fname)
        # Handle .tar.gz and .tgz specially
        if fname.endswith(".tar.gz") or fname.endswith(".tgz"):
            name = fname.rsplit('.', 2)[0]
        elif fname.endswith(".tar"):
            name = fname.rsplit('.', 1)[0]
        elif fname.endswith(".gz") and not fname.endswith(".tar.gz"):
            name = fname.rsplit('.', 1)[0]
        elif fname.endswith(".zip"):
            name = fname.rsplit('.', 1)[0]
        else:
            continue

        out_dir = os.path.join(target_dir, name)
        os.makedirs(out_dir, exist_ok=True)
        print(f"Extracting {fname} to {out_dir}...")
        extract_archive(fpath, out_dir)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("dir", help="Path to directory containing archives")
    args = parser.parse_args()

    extract_all_in_dir(args.dir)
