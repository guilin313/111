# cremi_dataset.py
import h5py
import torch
import numpy as np
from torch.utils.data import Dataset

class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 crop_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.crop_size = crop_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.volume_shape = self.raw.shape  # (D, H, W)
        self.starts = self.compute_sliding_window_starts(self.volume_shape, self.crop_size)

    def compute_sliding_window_starts(self, volume_shape, crop_size):
        starts = []
        for size, patch in zip(volume_shape, crop_size):
            pos = list(range(0, size - patch + 1, patch))
            if (size - patch) % patch != 0:
                pos.append(size - patch)
            starts.append(pos)
        return [(z, y, x) for z in starts[0] for y in starts[1] for x in starts[2]]

    def __len__(self):
        return len(self.starts)

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        z, y, x = self.starts[idx]
        dz, dy, dx = self.crop_size

        raw_crop = self.raw[z:z+dz, y:y+dy, x:x+dx].astype(np.float32)
        label_crop = self.labels[z:z+dz, y:y+dy, x:x+dx].astype(np.int64)

        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor

if __name__ == "__main__":
    import numpy as np

    H5_PATH = "./segementation_data/sample_C_20160501.hdf"  # ← 修改为你的实际路径

    # 多种 patch size 配置
    PATCH_SIZES = [
        (32, 320, 320),
        (32, 160, 160),
        (32, 96, 96),
        (32, 64, 64),
        (64, 160, 160)
    ]

    max_patches = 50  # 每种 patch size 只统计前 N 个 patch

    print(f"📊 比较多种 patch size 下的亲和图连接比例 (sample_C_20160501.hdf, 每种前 {max_patches} 个 patch)...\n")

    for patch_size in PATCH_SIZES:
        dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=patch_size)

        total_voxels = np.zeros(3, dtype=np.int64)
        total_ones = np.zeros(3, dtype=np.int64)

        N = min(max_patches, len(dataset))
        for i in range(N):
            _, aff = dataset[i]
            aff_np = aff.numpy()
            total_voxels += aff_np.shape[1] * aff_np.shape[2] * aff_np.shape[3]
            total_ones += aff_np.sum(axis=(1, 2, 3)).astype(np.int64)

        print(f"🧩 Patch size: {patch_size}")
        directions = ['z+', 'y+', 'x+']
        for i in range(3):
            ratio = total_ones[i] / total_voxels[i]
            print(f"  ➜ 方向 {directions[i]}: 连接比例 = {ratio:.4f} ({total_ones[i]}/{total_voxels[i]})")
        print("-" * 60)




if __name__ == "__main__":
    import numpy as np

    H5_PATH = "./segementation_data/sample_C_20160501.hdf"  # ← 修改为你的实际路径

    # 多种 patch size 配置
    PATCH_SIZES = [
        (32, 320, 320),
        (32, 160, 160),
        (32, 96, 96),
        (32, 64, 64),
        (64, 160, 160)
    ]

    max_patches = 50  # 每种 patch size 只统计前 N 个 patch

    print(f"📊 比较多种 patch size 下的亲和图连接比例 (sample_C_20160501.hdf, 每种前 {max_patches} 个 patch)...\n")

    for patch_size in PATCH_SIZES:
        dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=patch_size)

        total_voxels = np.zeros(3, dtype=np.int64)
        total_ones = np.zeros(3, dtype=np.int64)

        N = min(max_patches, len(dataset))
        for i in range(N):
            _, aff = dataset[i]
            aff_np = aff.numpy()
            total_voxels += aff_np.shape[1] * aff_np.shape[2] * aff_np.shape[3]
            total_ones += aff_np.sum(axis=(1, 2, 3)).astype(np.int64)

        print(f"🧩 Patch size: {patch_size}")
        directions = ['z+', 'y+', 'x+']
        for i in range(3):
            ratio = total_ones[i] / total_voxels[i]
            print(f"  ➜ 方向 {directions[i]}: 连接比例 = {ratio:.4f} ({total_ones[i]}/{total_voxels[i]})")
        print("-" * 60)


if __name__ == "__main__":
    import numpy as np

    H5_PATH = "./segementation_data/sample_C_20160501.hdf"  # ← 请根据你实际路径调整
    CROP_SIZE = (32, 320, 320)

    dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)

    total_voxels = np.zeros(3, dtype=np.int64)
    total_ones = np.zeros(3, dtype=np.int64)

    N = min(100, len(dataset))  # 检查前100个patch足够代表性
    print(f"📊 正在统计 sample_C_20160501.hdf 中前 {N} 个 patch 的亲和图连接比例...")

    for i in range(N):
        _, aff = dataset[i]  # aff: [3, D, H, W]
        aff_np = aff.numpy()
        total_voxels += aff_np.shape[1] * aff_np.shape[2] * aff_np.shape[3]
        total_ones += aff_np.sum(axis=(1, 2, 3)).astype(np.int64)

    directions = ['z+', 'y+', 'x+']
    for i in range(3):
        ratio = total_ones[i] / total_voxels[i]
        print(f"➡️ 方向 {directions[i]}: 连接比例 = {ratio:.4f} ({total_ones[i]}/{total_voxels[i]})")



# cremi_affinity_3d_dataset.py
import h5py
import torch
import numpy as np
from torch.utils.data import Dataset

class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 patch_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.patch_size = patch_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.volume_shape = self.raw.shape  # (D, H, W)
        self.starts = self.compute_sliding_window_starts(self.volume_shape, self.patch_size)

    def compute_sliding_window_starts(self, volume_shape, patch_size):
        starts = []
        for size, patch in zip(volume_shape, patch_size):
            pos = list(range(0, size - patch + 1, patch))
            if (size - patch) % patch != 0:
                pos.append(size - patch)
            starts.append(pos)
        return [(z, y, x) for z in starts[0] for y in starts[1] for x in starts[2]]

    def __len__(self):
        return len(self.starts)

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        z, y, x = self.starts[idx]
        dz, dy, dx = self.patch_size

        raw_crop = self.raw[z:z+dz, y:y+dy, x:x+dx].astype(np.float32)
        label_crop = self.labels[z:z+dz, y:y+dy, x:x+dx].astype(np.int64)

        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor





# cremi_affinity_3d_dataset.py
import h5py
import torch
import numpy as np
from torch.utils.data import Dataset
import random

class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 crop_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.crop_size = crop_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.D, self.H, self.W = self.raw.shape

    def __len__(self):
        return 10000  # number of random crops per epoch

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        zd, yh, xw = self.crop_size  # ✅ 确保使用传入 crop_size
        assert zd <= self.D and yh <= self.H and xw <= self.W, "Crop size must fit inside the volume"

        z = random.randint(0, self.D - zd)
        y = random.randint(0, self.H - yh)
        x = random.randint(0, self.W - xw)

        raw_crop = self.raw[z:z+zd, y:y+yh, x:x+xw].astype(np.float32)
        label_crop = self.labels[z:z+zd, y:y+yh, x:x+xw].astype(np.int64)

        assert raw_crop.shape == self.crop_size, f"Crop shape mismatch: got {raw_crop.shape}, expected {self.crop_size}"

        # 归一化 + 标准化
        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor
class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 crop_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.crop_size = crop_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.D, self.H, self.W = self.raw.shape

    def __len__(self):
        return 10000  # number of random crops per epoch

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        zd, yh, xw = self.crop_size
        z = random.randint(0, self.D - zd)
        y = random.randint(0, self.H - yh)
        x = random.randint(0, self.W - xw)

        raw_crop = self.raw[z:z+zd, y:y+yh, x:x+xw].astype(np.float32)
        #print("crop shape:", raw_crop.shape)
        label_crop = self.labels[z:z+zd, y:y+yh, x:x+xw].astype(np.int64)

        # 归一化 + 标准化
        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor



writer = SummaryWriter(log_dir=os.path.join(training_args.output_dir, "tb_samples"))
    log_dataset_samples(train_dataset, writer, tag_prefix="train", num_samples=5)
    log_dataset_samples(val_dataset, writer, tag_prefix="val", num_samples=3)
    writer.close()
    logger.info("✅ Wrote sample slices to TensorBoard.")

def log_dataset_samples(dataset, writer, tag_prefix="train", num_samples=5):
    for idx in range(min(num_samples, len(dataset))):
        data = dataset[idx]["pixel_values"]  # shape: [1, D, H, W]
        image = data[0, data.shape[1] // 2]   # 取中间层 [H, W]
        writer.add_image(f"{tag_prefix}_slice_{idx}", image.unsqueeze(0), global_step=0)



import os
import shutil
import random

# 设置路径
src_dir = 'path/to/your/tif_images'  # 原始文件夹路径，存放所有 .tif 图像
train_dir = 'path/to/save/train'  # 存储训练集的文件夹
val_dir = 'path/to/save/val'  # 存储验证集的文件夹

# 创建训练集和验证集的目录
os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

# 获取所有 .tif 文件
tif_files = [f for f in os.listdir(src_dir) if f.endswith('.tif')]

# 打乱文件顺序
random.shuffle(tif_files)

# 划分训练集和验证集
split_ratio = 0.9
train_size = int(len(tif_files) * split_ratio)

train_files = tif_files[:train_size]
val_files = tif_files[train_size:]

# 复制训练集文件
for file in train_files:
    src_path = os.path.join(src_dir, file)
    dst_path = os.path.join(train_dir, file)
    shutil.copy(src_path, dst_path)

# 复制验证集文件
for file in val_files:
    src_path = os.path.join(src_dir, file)
    dst_path = os.path.join(val_dir, file)
    shutil.copy(src_path, dst_path)

print(f"训练集包含 {len(train_files)} 张图片")
print(f"验证集包含 {len(val_files)} 张图片")





import os
import torch
import random
import numpy as np
import tifffile as tiff
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader

class TIFDataset(Dataset):
    def __init__(self, data_dir, augment=True):
        self.data_dir = data_dir
        self.file_list = sorted(os.listdir(data_dir))
        self.augment = augment

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        file_path = os.path.join(self.data_dir, self.file_list[idx])
        image = tiff.imread(file_path)  # (D, H, W)
        
        # 归一化到 [0,1]
        image = image.astype('float32') / 255.0  

        # 3D 预处理
        image = self.preprocess(image)

        # 转换为 Tensor
        image = torch.tensor(image).unsqueeze(0)  # [C=1, D, H, W]
        return image

    def preprocess(self, image):
        """ 数据预处理：标准化 & 数据增强 """
        # 标准化（减均值，除以标准差）
        image = (image - np.mean(image)) / (np.std(image) + 1e-5)

        if self.augment:
            image = self.augment_data(image)
        
        return image

    def augment_data(self, image):
        """ 数据增强：随机翻转、旋转、高斯噪声 """
        if random.random() > 0.5:
            image = np.flip(image, axis=1)  # 左右翻转
        if random.random() > 0.5:
            image = np.flip(image, axis=2)  # 上下翻转
        if random.random() > 0.5:
            image = np.flip(image, axis=0)  # 深度翻转

        # 旋转 90/180/270 度
        if random.random() > 0.5:
            k = random.choice([1, 2, 3])
            image = np.rot90(image, k=k, axes=(1, 2))  

        # 添加高斯噪声
        if random.random() > 0.7:
            noise = np.random.normal(0, 0.01, image.shape)
            image = np.clip(image + noise, 0, 1)

        return image

def get_dataloader(data_dir, batch_size=4, augment=True):
    dataset = TIFDataset(data_dir, augment=augment)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)


import os
import zipfile
import tarfile
import gzip
import shutil

def extract_archive(archive_path, output_dir):
    try:
        if archive_path.endswith(".zip"):
            with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                zip_ref.extractall(output_dir)
        elif archive_path.endswith((".tar.gz", ".tgz", ".tar")):
            with tarfile.open(archive_path, 'r:*') as tar_ref:
                tar_ref.extractall(output_dir)
        elif archive_path.endswith(".gz") and not archive_path.endswith(".tar.gz"):
            with gzip.open(archive_path, 'rb') as f_in:
                out_path = os.path.join(output_dir, os.path.basename(archive_path)[:-3])
                with open(out_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
        else:
            print(f"Unsupported format: {archive_path}")
    except Exception as e:
        print(f"❌ Failed to extract {archive_path}: {e}")

def extract_all_in_dir(target_dir):
    for fname in os.listdir(target_dir):
        fpath = os.path.join(target_dir, fname)
        if not os.path.isfile(fpath):
            continue

        name, ext = os.path.splitext(fname)
        # Handle .tar.gz and .tgz specially
        if fname.endswith(".tar.gz") or fname.endswith(".tgz"):
            name = fname.rsplit('.', 2)[0]
        elif fname.endswith(".tar"):
            name = fname.rsplit('.', 1)[0]
        elif fname.endswith(".gz") and not fname.endswith(".tar.gz"):
            name = fname.rsplit('.', 1)[0]
        elif fname.endswith(".zip"):
            name = fname.rsplit('.', 1)[0]
        else:
            continue

        out_dir = os.path.join(target_dir, name)
        os.makedirs(out_dir, exist_ok=True)
        print(f"Extracting {fname} to {out_dir}...")
        extract_archive(fpath, out_dir)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("dir", help="Path to directory containing archives")
    args = parser.parse_args()

    extract_all_in_dir(args.dir)
