import os
import glob
import re
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unetR import MAEUNETRSkipSegmentation
from transformers import ViTMAEConfig

# === Config ===
H5_PATHS = [
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_A_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_B_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_C_20160501.hdf",
]
CHECKPOINT_DIR = "./checkpoints_affinity3d4"
CHECKPOINT = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
NUM_EPOCHS = 3000
NUM_CLASSES = 3
LR = 1e-4
WARMUP_EPOCHS = 10
LOG_DIR = "./logs_affinity3d4"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# === Focal Loss ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0)):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.register_buffer(
            'channel_weights',
            torch.tensor(channel_weights).view(1, 3, 1, 1, 1)
        )

    def forward(self, input, target):
        bce_loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')
        prob = torch.sigmoid(input)
        focal_weight = self.alpha * (1 - prob) ** self.gamma * target + \
                       (1 - self.alpha) * prob ** self.gamma * (1 - target)
        focal_loss = focal_weight * bce_loss
        channel_weights = self.channel_weights.to(input.device)
        return (focal_loss * channel_weights).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
config = ViTMAEConfig.from_pretrained(CHECKPOINT)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNETRSkipSegmentation(CHECKPOINT, config, num_classes=NUM_CLASSES).to(DEVICE)

optimizer = optim.AdamW(model.parameters(), lr=LR)
criterion = FocalLoss(gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0))

# === Warmup Scheduler + ReduceLROnPlateau ===
def warmup_lambda(epoch):
    if epoch < WARMUP_EPOCHS:
        return float(epoch + 1) / WARMUP_EPOCHS
    return 1.0

warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_lambda)
plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=10, threshold=1e-4, verbose=True
)

writer = SummaryWriter(LOG_DIR)

# === Auto Resume Latest Checkpoint ===
def get_latest_checkpoint(path):
    checkpoint_files = glob.glob(os.path.join(path, "mae3d_unet_epoch*.pth"))
    if not checkpoint_files:
        return None
    def extract_epoch(filename):
        match = re.search(r"epoch(\d+)", filename)
        return int(match.group(1)) if match else -1
    checkpoint_files.sort(key=extract_epoch, reverse=True)
    return checkpoint_files[0]

START_EPOCH = 0
resume_path = get_latest_checkpoint(CHECKPOINT_DIR)
if resume_path is not None:
    print(f"ðŸ” Resuming training from: {resume_path}")
    checkpoint = torch.load(resume_path, map_location=DEVICE)
    model.load_state_dict(checkpoint["model_state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
    warmup_scheduler.last_epoch = checkpoint["epoch"] - 1
    plateau_scheduler.last_epoch = checkpoint["epoch"] - 1
    START_EPOCH = checkpoint["epoch"]
else:
    print("ðŸš€ Starting training from scratch")

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    correct = (preds == targets).float().mean()
    return correct.item()

# === Training Loop ===
for epoch in range(START_EPOCH, NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs, targets, boundary = inputs.to(DEVICE), targets.to(DEVICE), boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        weight = 1.0 + 1.0 * boundary.unsqueeze(1)
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs, targets, boundary = inputs.to(DEVICE), targets.to(DEVICE), boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 1.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            val_loss += loss.mean().item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", optimizer.param_groups[0]["lr"], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    # === Scheduler step ===
    if epoch < WARMUP_EPOCHS:
        warmup_scheduler.step()
    else:
        plateau_scheduler.step(avg_val_loss)

    # === Save Checkpoint ===
    if (epoch + 1) % 10 == 0:
        torch.save({
            "epoch": epoch + 1,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
        }, os.path.join(CHECKPOINT_DIR, f"unetr_epoch{epoch+1}.pth"))

writer.close()



import os
import glob
import re
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset
from model_unetr import get_unetr_model

# === Config ===
H5_PATHS = [
    "./segementation_data/sample_A_20160501.hdf",
    "./segementation_data/sample_B_20160501.hdf",
    "./segementation_data/sample_C_20160501.hdf",
]
CHECKPOINT_DIR = "./checkpoints_unetr_affinity3d1"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 2
NUM_EPOCHS = 3000
NUM_CLASSES = 3
LR = 5e-4
LOG_DIR = "./logs_unetr_affinity3d1"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# === Focal Loss ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0)):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.register_buffer(
            'channel_weights',
            torch.tensor(channel_weights).view(1, NUM_CLASSES, 1, 1, 1)
        )

    def forward(self, input, target):
        bce_loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')
        prob = torch.sigmoid(input)
        focal_weight = self.alpha * (1 - prob) ** self.gamma * target + \
                       (1 - self.alpha) * prob ** self.gamma * (1 - target)
        focal_loss = focal_weight * bce_loss
        return (focal_loss * self.channel_weights.to(input.device)).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
model = get_unetr_model(img_size=CROP_SIZE, in_channels=1, out_channels=NUM_CLASSES).to(DEVICE)
optimizer = optim.AdamW(model.parameters(), lr=LR)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)
criterion = FocalLoss(gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0))

# === TensorBoard Writer ===
writer = SummaryWriter(LOG_DIR)

# === Resume Checkpoint ===
def get_latest_checkpoint(path):
    checkpoint_files = glob.glob(os.path.join(path, "unetr_epoch*.pth"))
    if not checkpoint_files:
        return None
    def extract_epoch(filename):
        match = re.search(r"epoch(\d+)", filename)
        return int(match.group(1)) if match else -1
    checkpoint_files.sort(key=extract_epoch, reverse=True)
    return checkpoint_files[0]

START_EPOCH = 0
resume_path = get_latest_checkpoint(CHECKPOINT_DIR)
if resume_path is not None:
    print(f"ðŸ” Resuming training from: {resume_path}")
    checkpoint = torch.load(resume_path, map_location=DEVICE)
    model.load_state_dict(checkpoint["model_state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
    scheduler.load_state_dict(checkpoint["scheduler_state_dict"])
    START_EPOCH = checkpoint["epoch"]
else:
    print("ðŸš€ Starting training from scratch")

# === Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    return (preds == targets).float().mean().item()

# === Training Loop ===
for epoch in range(START_EPOCH, NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs, targets, boundary = inputs.to(DEVICE), targets.to(DEVICE), boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        weight = 1.0 + 1.0 * boundary.unsqueeze(1)
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs, targets, boundary = inputs.to(DEVICE), targets.to(DEVICE), boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 1.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            val_loss += loss.mean().item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    scheduler.step()

    if (epoch + 1) % 10 == 0:
        torch.save({
            "epoch": epoch + 1,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "scheduler_state_dict": scheduler.state_dict(),
        }, os.path.join(CHECKPOINT_DIR, f"unetr_epoch{epoch+1}.pth"))

writer.close()




import os
import glob
import re
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset
from model_unetr import get_unetr_model

# === Config ===
H5_PATHS = [
    "/path/to/sample_A_20160501.hdf",
    "/path/to/sample_B_20160501.hdf",
    "/path/to/sample_C_20160501.hdf",
]
CHECKPOINT_DIR = "./checkpoints_unetr_affinity3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 2
NUM_EPOCHS = 300
NUM_CLASSES = 3
LR = 1e-4
WARMUP_EPOCHS = 10
LOG_DIR = "./logs_unetr_affinity3d"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# === Focal Loss ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0)):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.register_buffer(
            'channel_weights',
            torch.tensor(channel_weights).view(1, NUM_CLASSES, 1, 1, 1)
        )

    def forward(self, input, target):
        bce_loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')
        prob = torch.sigmoid(input)
        focal_weight = self.alpha * (1 - prob) ** self.gamma * target + \
                       (1 - self.alpha) * prob ** self.gamma * (1 - target)
        focal_loss = focal_weight * bce_loss
        return (focal_loss * self.channel_weights.to(input.device)).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
model = get_unetr_model(img_size=CROP_SIZE, in_channels=1, out_channels=NUM_CLASSES).to(DEVICE)
optimizer = optim.AdamW(model.parameters(), lr=LR)
criterion = FocalLoss(gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0))

# === Warmup Scheduler + ReduceLROnPlateau ===
def warmup_lambda(epoch):
    if epoch < WARMUP_EPOCHS:
        return float(epoch + 1) / WARMUP_EPOCHS
    return 1.0

warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_lambda)
plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=10, threshold=1e-4, verbose=True
)

# === TensorBoard Writer ===
writer = SummaryWriter(LOG_DIR)

# === Resume Checkpoint ===
def get_latest_checkpoint(path):
    checkpoint_files = glob.glob(os.path.join(path, "unetr_epoch*.pth"))
    if not checkpoint_files:
        return None
    def extract_epoch(filename):
        match = re.search(r"epoch(\d+)", filename)
        return int(match.group(1)) if match else -1
    checkpoint_files.sort(key=extract_epoch, reverse=True)
    return checkpoint_files[0]

START_EPOCH = 0
resume_path = get_latest_checkpoint(CHECKPOINT_DIR)
if resume_path is not None:
    print(f"ðŸ” Resuming training from: {resume_path}")
    checkpoint = torch.load(resume_path, map_location=DEVICE)
    model.load_state_dict(checkpoint["model_state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
    warmup_scheduler.last_epoch = checkpoint["epoch"] - 1
    plateau_scheduler.last_epoch = checkpoint["epoch"] - 1
    START_EPOCH = checkpoint["epoch"]
else:
    print("ðŸš€ Starting training from scratch")

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    return (preds == targets).float().mean().item()

# === Training Loop ===
for epoch in range(START_EPOCH, NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs, targets, boundary = inputs.to(DEVICE), targets.to(DEVICE), boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        weight = 1.0 + 4.0 * boundary.unsqueeze(1)
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs, targets, boundary = inputs.to(DEVICE), targets.to(DEVICE), boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 4.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            val_loss += loss.mean().item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", optimizer.param_groups[0]["lr"], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    # === Scheduler step ===
    if epoch < WARMUP_EPOCHS:
        warmup_scheduler.step()
    else:
        plateau_scheduler.step(avg_val_loss)

    # === Save Checkpoint ===
    if (epoch + 1) % 10 == 0:
        torch.save({
            "epoch": epoch + 1,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
        }, os.path.join(CHECKPOINT_DIR, f"unetr_epoch{epoch+1}.pth"))

writer.close()



import os
import glob
import re
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unetR import MAEUNETRSkipSegmentation
from transformers import ViTMAEConfig

# === Config ===
H5_PATHS = [
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_A_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_B_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_C_20160501.hdf",
]
CHECKPOINT_DIR = "./checkpoints_affinity3d"
CHECKPOINT = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 2
NUM_EPOCHS = 300
NUM_CLASSES = 3
LR = 1e-5
LOG_DIR = "./logs_affinity3d2"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# === Focal Loss ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0)):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.register_buffer(
            'channel_weights',
            torch.tensor(channel_weights).view(1, 3, 1, 1, 1)
        )

    def forward(self, input, target):
        bce_loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')
        prob = torch.sigmoid(input)
        focal_weight = self.alpha * (1 - prob) ** self.gamma * target + \
                       (1 - self.alpha) * prob ** self.gamma * (1 - target)
        focal_loss = focal_weight * bce_loss
        channel_weights = self.channel_weights.to(input.device)
        return (focal_loss * channel_weights).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
config = ViTMAEConfig.from_pretrained(CHECKPOINT)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNETRSkipSegmentation(CHECKPOINT, config, num_classes=NUM_CLASSES).to(DEVICE)

optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)
criterion = FocalLoss(gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0))

writer = SummaryWriter(LOG_DIR)

# === Auto Resume Latest Checkpoint ===
def get_latest_checkpoint(path):
    checkpoint_files = glob.glob(os.path.join(path, "mae3d_unet_epoch*.pth"))
    if not checkpoint_files:
        return None
    def extract_epoch(filename):
        match = re.search(r"epoch(\d+)", filename)
        return int(match.group(1)) if match else -1
    checkpoint_files.sort(key=extract_epoch, reverse=True)
    return checkpoint_files[0]

START_EPOCH = 0
resume_path = get_latest_checkpoint(CHECKPOINT_DIR)
if resume_path is not None:
    print(f"ðŸ” Resuming training from: {resume_path}")
    checkpoint = torch.load(resume_path, map_location=DEVICE)
    model.load_state_dict(checkpoint["model_state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
    scheduler.load_state_dict(checkpoint["scheduler_state_dict"])
    START_EPOCH = checkpoint["epoch"]
else:
    print("ðŸš€ Starting training from scratch")

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    correct = (preds == targets).float().mean()
    return correct.item()

# === Training Loop ===
for epoch in range(START_EPOCH, NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs = inputs.to(DEVICE)
        targets = targets.to(DEVICE)
        boundary = boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        weight = 1.0 + 4.0 * boundary.unsqueeze(1)
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs = inputs.to(DEVICE)
            targets = targets.to(DEVICE)
            boundary = boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 4.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            loss = loss.mean()
            val_loss += loss.item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    scheduler.step()

    if (epoch + 1) % 10 == 0:
        torch.save({
            "epoch": epoch + 1,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "scheduler_state_dict": scheduler.state_dict(),
        }, os.path.join(CHECKPOINT_DIR, f"mae3d_unet_epoch{epoch+1}.pth"))

writer.close()





import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset  # è¯·ç¡®ä¿ä½ çš„ç±»ä¿å­˜åœ¨æ­¤æ–‡ä»¶
from model_unetr import get_unetr_model  # ä½¿ç”¨ monai çš„ UNETR

# === Config ===
H5_PATHS = [
    "/path/to/sample_A_20160501.hdf",
    "/path/to/sample_B_20160501.hdf",
    "/path/to/sample_C_20160501.hdf",
]
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 2
NUM_EPOCHS = 300
NUM_CLASSES = 3
LR = 1e-4
LOG_DIR = "./logs_unetr_affinity3d"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === Focal Loss with channel weights ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0)):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.register_buffer(
            'channel_weights',
            torch.tensor(channel_weights).view(1, NUM_CLASSES, 1, 1, 1)
        )

    def forward(self, input, target):
        bce_loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')
        prob = torch.sigmoid(input)
        focal_weight = self.alpha * (1 - prob) ** self.gamma * target + \
                       (1 - self.alpha) * prob ** self.gamma * (1 - target)
        focal_loss = focal_weight * bce_loss
        return (focal_loss * self.channel_weights.to(input.device)).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
model = get_unetr_model(img_size=CROP_SIZE, in_channels=1, out_channels=NUM_CLASSES).to(DEVICE)
total = sum(p.numel() for p in model.parameters())
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Total params: {total}, Trainable: {trainable}")

# === Optimizer, Scheduler, Loss ===
optimizer = optim.AdamW(model.parameters(), lr=LR)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)
criterion = FocalLoss(gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0))

# === Logging ===
writer = SummaryWriter(LOG_DIR)

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    correct = (preds == targets).float().mean()
    return correct.item()

# === Training Loop ===
for epoch in range(NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs = inputs.to(DEVICE)
        targets = targets.to(DEVICE)
        boundary = boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)  # [B, 3, D, H, W]
        weight = 1.0 + 4.0 * boundary.unsqueeze(1)  # boundary mask
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs = inputs.to(DEVICE)
            targets = targets.to(DEVICE)
            boundary = boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 4.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            loss = loss.mean()
            val_loss += loss.item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    scheduler.step()

    # Save every 10 epochs
    if (epoch + 1) % 10 == 0:
        os.makedirs("checkpoints_unetr_affinity3d", exist_ok=True)
        torch.save(model.state_dict(), f"checkpoints_unetr_affinity3d/unetr_epoch{epoch+1}.pth")

writer.close()




import os
import glob
import re
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2SkipSegmentation
from transformers import ViTMAEConfig

# === Config ===
H5_PATHS = [
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_A_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_B_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_C_20160501.hdf",
]
CHECKPOINT_DIR = "./checkpoints_affinity3d2"
CHECKPOINT = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 2
NUM_EPOCHS = 300
NUM_CLASSES = 3
LR = 1e-5
LOG_DIR = "./logs_affinity3d"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# === Focal Loss ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0)):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.register_buffer(
            'channel_weights',
            torch.tensor(channel_weights).view(1, 3, 1, 1, 1)
        )

    def forward(self, input, target):
        bce_loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')
        prob = torch.sigmoid(input)
        focal_weight = self.alpha * (1 - prob) ** self.gamma * target + \
                       (1 - self.alpha) * prob ** self.gamma * (1 - target)
        focal_loss = focal_weight * bce_loss
        channel_weights = self.channel_weights.to(input.device)
        return (focal_loss * channel_weights).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
config = ViTMAEConfig.from_pretrained(CHECKPOINT)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2SkipSegmentation(CHECKPOINT, config, num_classes=NUM_CLASSES).to(DEVICE)

optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)
criterion = FocalLoss(gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0))

writer = SummaryWriter(LOG_DIR)

# === Auto Resume Latest Checkpoint ===
def get_latest_checkpoint(path):
    checkpoint_files = glob.glob(os.path.join(path, "mae3d_unet_epoch*.pth"))
    if not checkpoint_files:
        return None
    def extract_epoch(filename):
        match = re.search(r"epoch(\d+)", filename)
        return int(match.group(1)) if match else -1
    checkpoint_files.sort(key=extract_epoch, reverse=True)
    return checkpoint_files[0]

START_EPOCH = 0
resume_path = get_latest_checkpoint(CHECKPOINT_DIR)
if resume_path is not None:
    print(f"ðŸ” Resuming training from: {resume_path}")
    checkpoint = torch.load(resume_path, map_location=DEVICE)
    model.load_state_dict(checkpoint["model_state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
    scheduler.load_state_dict(checkpoint["scheduler_state_dict"])
    START_EPOCH = checkpoint["epoch"]
else:
    print("ðŸš€ Starting training from scratch")

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    correct = (preds == targets).float().mean()
    return correct.item()

# === Training Loop ===
for epoch in range(START_EPOCH, NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs = inputs.to(DEVICE)
        targets = targets.to(DEVICE)
        boundary = boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        weight = 1.0 + 4.0 * boundary.unsqueeze(1)
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs = inputs.to(DEVICE)
            targets = targets.to(DEVICE)
            boundary = boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 4.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            loss = loss.mean()
            val_loss += loss.item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    scheduler.step()

    if (epoch + 1) % 10 == 0:
        torch.save({
            "epoch": epoch + 1,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "scheduler_state_dict": scheduler.state_dict(),
        }, os.path.join(CHECKPOINT_DIR, f"mae3d_unet_epoch{epoch+1}.pth"))

writer.close()



import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2SkipSegmentation
from transformers import ViTMAEConfig

# === Config ===
H5_PATHS = [
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_A_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_B_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_C_20160501.hdf",
]
CHECKPOINT = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 2
NUM_EPOCHS = 300
NUM_CLASSES = 3
LR = 1e-5
LOG_DIR = "./logs_affinity3d"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === Focal Loss with no channel_weights (insert if needed) ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0)):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.register_buffer(
            'channel_weights',
            torch.tensor(channel_weights).view(1, 3, 1, 1, 1)
        )

    def forward(self, input, target):
        # input: [B, 3, D, H, W]
        # target: same shape
        bce_loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')
        prob = torch.sigmoid(input)
        focal_weight = self.alpha * (1 - prob) ** self.gamma * target + \
                       (1 - self.alpha) * prob ** self.gamma * (1 - target)
        focal_loss = focal_weight * bce_loss
        channel_weights = self.channel_weights.to(input.device)
        return (focal_loss * channel_weights).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
config = ViTMAEConfig.from_pretrained(CHECKPOINT)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2SkipSegmentation(CHECKPOINT, config, num_classes=NUM_CLASSES).to(DEVICE)

total = sum(p.numel() for p in model.parameters())
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Total params: {total}, Trainable: {trainable}")

# === Optimizer, Scheduler, Loss ===
optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)
criterion = FocalLoss(
    gamma=2.0,
    alpha=0.25,
    channel_weights=(1.0, 1.0, 1.0)
)

# === Logging ===
writer = SummaryWriter(LOG_DIR)

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    correct = (preds == targets).float().mean()
    return correct.item()

# === Training Loop ===
for epoch in range(NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs = inputs.to(DEVICE)
        targets = targets.to(DEVICE)
        boundary = boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        weight = 1.0 + 4.0 * boundary.unsqueeze(1)
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs = inputs.to(DEVICE)
            targets = targets.to(DEVICE)
            boundary = boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 4.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            loss = loss.mean()
            val_loss += loss.item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    scheduler.step()

    if (epoch + 1) % 10 == 0:
        os.makedirs("checkpoints_affinity3d2", exist_ok=True)
        torch.save(model.state_dict(), f"./checkpoints_affinity3d2/mae3d_unet_epoch{epoch+1}.pth")

writer.close()



total = sum(p.numel() for p in model.parameters())
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Total params: {total}, Trainable: {trainable}")

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig

# === Config ===
H5_PATHS = [
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_A_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_B_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_C_20160501.hdf",
]
CHECKPOINT = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d"
CROP_SIZE = (32, 160, 160)
BATCH_SIZE = 2
NUM_EPOCHS = 300
NUM_CLASSES = 3
LR = 5e-4
LOG_DIR = "./logs_affinity3d"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === Focal Loss with no channel_weights (insert if needed) ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, alpha=0.25, channel_weights=(1.0, 1.0, 1.0)):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.register_buffer(
            'channel_weights',
            torch.tensor(channel_weights).view(1, 3, 1, 1, 1)
        )

    def forward(self, input, target):
        # input: [B, 3, D, H, W]
        # target: same shape
        bce_loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')
        prob = torch.sigmoid(input)
        focal_weight = self.alpha * (1 - prob) ** self.gamma * target + \
                       (1 - self.alpha) * prob ** self.gamma * (1 - target)
        focal_loss = focal_weight * bce_loss
        return (focal_loss * self.channel_weights).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
config = ViTMAEConfig.from_pretrained(CHECKPOINT)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CHECKPOINT, config, num_classes=NUM_CLASSES).to(DEVICE)

# === Optimizer, Scheduler, Loss ===
optimizer = optim.AdamW(model.parameters(), lr=LR)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)
criterion = FocalLoss(
    gamma=2.0,
    alpha=0.25,
    channel_weights=(3.0, 1.0, 1.0)  # å¼ºè°ƒ z+ é€šé“
)

# === Logging ===
writer = SummaryWriter(LOG_DIR)

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    correct = (preds == targets).float().mean()
    return correct.item()

# === Training Loop ===
for epoch in range(NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs = inputs.to(DEVICE)
        targets = targets.to(DEVICE)
        boundary = boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        weight = 1.0 + 4.0 * boundary.unsqueeze(1)
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs = inputs.to(DEVICE)
            targets = targets.to(DEVICE)
            boundary = boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 4.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            loss = loss.mean()
            val_loss += loss.item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    scheduler.step()

    if (epoch + 1) % 10 == 0:
        os.makedirs("./checkpoints_affinity3d2", exist_ok=True)
        torch.save(model.state_dict(), f"./checkpoints_affinity3d2/mae3d_unet_epoch{epoch+1}.pth")

writer.close()



import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig

# === Config ===
H5_PATHS = [
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_A_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_B_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_C_20160501.hdf",
]
CHECKPOINT = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d"
CROP_SIZE = (32, 160, 160)
BATCH_SIZE = 2
NUM_EPOCHS = 300
NUM_CLASSES = 3
LR = 5e-4
LOG_DIR = "./logs_affinity3d"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === Focal Loss with no channel_weights (insert if needed) ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0):
        super().__init__()
        self.gamma = gamma
        self.bce = nn.BCEWithLogitsLoss(reduction='none')

    def forward(self, input, target):
        bce_loss = self.bce(input, target)
        prob = torch.sigmoid(input)
        focal_weight = (1 - prob) ** self.gamma * target + prob ** self.gamma * (1 - target)
        return focal_weight * bce_loss

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
config = ViTMAEConfig.from_pretrained(CHECKPOINT)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CHECKPOINT, config, num_classes=NUM_CLASSES).to(DEVICE)

# === Optimizer, Scheduler, Loss ===
optimizer = optim.AdamW(model.parameters(), lr=LR)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)
criterion = FocalLoss(gamma=2.0)

# === Logging ===
writer = SummaryWriter(LOG_DIR)

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    correct = (preds == targets).float().mean()
    return correct.item()

# === Training Loop ===
for epoch in range(NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets, boundary in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs = inputs.to(DEVICE)
        targets = targets.to(DEVICE)
        boundary = boundary.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        weight = 1.0 + 4.0 * boundary.unsqueeze(1)
        loss = criterion(outputs, targets) * weight
        loss = loss.mean()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets, boundary in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs = inputs.to(DEVICE)
            targets = targets.to(DEVICE)
            boundary = boundary.to(DEVICE)

            outputs = model(inputs)
            weight = 1.0 + 4.0 * boundary.unsqueeze(1)
            loss = criterion(outputs, targets) * weight
            loss = loss.mean()
            val_loss += loss.item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    scheduler.step()

    if (epoch + 1) % 10 == 0:
        os.makedirs("./checkpoints_affinity3d1", exist_ok=True)
        torch.save(model.state_dict(), f"./checkpoints_affinity3d1/mae3d_unet_epoch{epoch+1}.pth")

writer.close()


import torch
import torch.optim as optim
from torch.nn.parallel import DataParallel
from dataset import get_dataloader
from model import MAE3D
from config import args
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import numpy as np

# è‡ªå®šä¹‰ ViT ç¼–ç å™¨ & è§£ç å™¨
encoder = ...  # ä½ çš„ ViT 3D ç¼–ç å™¨
decoder = ...  # ä½ çš„ ViT 3D è§£ç å™¨

# åˆå§‹åŒ–æ¨¡åž‹
model = MAE3D(encoder, decoder, args)
model = DataParallel(model).cuda()

# è®­ç»ƒå‚æ•°
optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.num_epochs)
dataloader = get_dataloader("/path/to/your/tif_data", batch_size=args.batch_size)

# AMP è®­ç»ƒ
scaler = torch.cuda.amp.GradScaler()
accumulation_steps = 4  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°

# TensorBoard è®°å½•
writer = SummaryWriter(log_dir="runs/mae3d")

# è®­ç»ƒå¾ªçŽ¯
for epoch in range(args.num_epochs):
    model.train()
    epoch_loss = 0.0
    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f"Epoch {epoch+1}/{args.num_epochs}")
    correct, total = 0, 0
    
    for i, (batch) in progress_bar:
        batch = batch.cuda()
        optimizer.zero_grad()

        with torch.cuda.amp.autocast():  # æ··åˆç²¾åº¦è®¡ç®—
            loss, original, recon, masked = model(batch, return_image=True)
            loss = loss / accumulation_steps  # è¿›è¡Œæ¢¯åº¦ç´¯ç§¯
        
        scaler.scale(loss).backward()  # åå‘ä¼ æ’­
        
        if (i + 1) % accumulation_steps == 0:
            scaler.step(optimizer)  # æ›´æ–°å‚æ•°
            scaler.update()  # æ›´æ–° Scaler
            optimizer.zero_grad()
        
        epoch_loss += loss.item() * accumulation_steps  # è¿˜åŽŸ Loss è®¡ç®—
        progress_bar.set_postfix(loss=loss.item() * accumulation_steps)
        
        # è®¡ç®—ç²¾åº¦
        recon_error = torch.abs(original - recon).mean(dim=(1, 2, 3))  # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„é‡å»ºè¯¯å·®
        batch_accuracy = torch.exp(-recon_error).mean().item()  # è½¬æ¢ä¸ºç²¾åº¦
        correct += batch_accuracy * batch.size(0)
        total += batch.size(0)
    
    scheduler.step()  # å­¦ä¹ çŽ‡è¡°å‡
    avg_loss = epoch_loss / len(dataloader)
    accuracy = correct / total  # è®¡ç®—å¹³å‡ç²¾åº¦
    print(f"Epoch [{epoch+1}/{args.num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}")
    writer.add_scalar("Loss/train", avg_loss, epoch)
    writer.add_scalar("Accuracy/train", accuracy, epoch)

# å…³é—­ TensorBoard è®°å½•
writer.close()

# ä¿å­˜æ¨¡åž‹
torch.save(model.state_dict(), "mae3d_model.pth")
