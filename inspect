import os
import torch
from mae3d_unet_finetune import MAEUNet2SkipSegmentation
from transformers import ViTMAEConfig

# === é…ç½®è·¯å¾„ ===
CHECKPOINT_DIR = "./checkpoints_affinity3d2"
CHECKPOINT_NAME = "mae3d_unet_epoch60.pth"  # æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ checkpoint æ–‡ä»¶
PRETRAINED_BACKBONE = "./output/vitmae3d"   # ViT-MAE é¢„è®­ç»ƒæƒé‡è·¯å¾„
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === æ¨¡å‹è¾“å…¥ç›¸å…³å‚æ•° ===
CROP_SIZE = (32, 320, 320)
NUM_CLASSES = 3

# === åŠ è½½æ¨¡å‹ç»“æ„ä¸æƒé‡ ===
config = ViTMAEConfig.from_pretrained(PRETRAINED_BACKBONE)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0

model = MAEUNet2SkipSegmentation(PRETRAINED_BACKBONE, config, num_classes=NUM_CLASSES)
checkpoint_path = os.path.join(CHECKPOINT_DIR, CHECKPOINT_NAME)
state_dict = torch.load(checkpoint_path, map_location=DEVICE)
model.load_state_dict(state_dict["model_state_dict"])
model.to(DEVICE)
model.eval()

print("âœ… æ¨¡å‹æˆåŠŸåŠ è½½ï¼")

# === æ‰“å°å®Œæ•´æ¨¡å‹ç»“æ„æ ‘ ===
print("\nğŸ§© å®Œæ•´æ¨¡å‹ç»“æ„:")
print(model)

# === æ‰“å° Encoder å’Œ Decoder ç»“æ„ ===
print("\nğŸ“¦ Encoder éƒ¨åˆ†ï¼ˆViT-MAEï¼‰:")
print(model.encoder)

print("\nğŸ”§ Decoder éƒ¨åˆ†ï¼ˆU-Netï¼‰:")
print(model.decoder)

# === å¯é€‰ï¼šå‰å‘ä¸€æ¬¡ï¼Œæ£€æŸ¥è¾“å‡ºå½¢çŠ¶ ===
with torch.no_grad():
    dummy_input = torch.randn(1, 4, *CROP_SIZE).to(DEVICE)
    output = model(dummy_input)
    print(f"\nğŸ§  æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
