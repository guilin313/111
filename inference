import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch180.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 127.91 / 255
STD = 28 / 255
THRESHOLD = 0.9

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=True))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD +MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())


        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        tifffile.imwrite(os.path.join(SAVE_DIR,f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))  # 不加阈值

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")


        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        print(f"z_aff ratio: {z_aff.sum() / z_aff.size:.4f}")
        print(f"y_aff ratio: {y_aff.sum() / y_aff.size:.4f}")
        print(f"x_aff ratio: {x_aff.sum() / x_aff.size:.4f}")


        # Save z_aff debug as uint8 for visualization
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))

        # === Connected component labeling ===
        aff_mask = np.ones_like(z_aff, dtype=bool)
        aff_mask[:-1] &= z_aff[:-1]
        aff_mask[:, :-1] &= y_aff[:, :-1]
        aff_mask[:, :, :-1] &= x_aff[:, :, :-1]

        instance = label(aff_mask, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch100.pth"
CONFIG_PATH = "./output/vitmae3d/checkpoint-100000"
H5_PATH = "./data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
THRESHOLD = 0.5

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = (raw_np * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())

        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        # Save z_aff debug as uint8 for visualization
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))

        # === Connected component labeling ===
        aff_mask = np.ones_like(z_aff, dtype=bool)
        aff_mask[:-1] &= z_aff[:-1]
        aff_mask[:, :-1] &= y_aff[:, :-1]
        aff_mask[:, :, :-1] &= x_aff[:, :, :-1]

        instance = label(aff_mask, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



# inference_affinity_3d.py
import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader
from skimage.measure import label
import h5py
from cremi_affinity_3d_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch100.pth"
CONFIG_PATH = "./output/vitmae3d/checkpoint-100000"
H5_PATH = "./data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
PATCH_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
THRESHOLD = 0.5

# === Load full labels for ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, patch_size=PATCH_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = torch.utils.data.Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = PATCH_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# === Loss for reporting ===
criterion = nn.BCEWithLogitsLoss()

# === Inference & reconstruction ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        restored_raws.append(raw_np)

        # Save corresponding GT label patch
        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = PATCH_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())

        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")

        # === Save z_aff debug image ===
        z_aff = (pred[0] > THRESHOLD).astype(np.uint8)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff)

        y_aff = (pred[1] > THRESHOLD).astype(np.uint8)
        x_aff = (pred[2] > THRESHOLD).astype(np.uint8)

        D, H, W = z_aff.shape
        visited = np.zeros((D, H, W), dtype=bool)
        labels = np.zeros((D, H, W), dtype=np.int32)
        current_id = 1

        def dfs(z, y, x):
            stack = [(z, y, x)]
            while stack:
                cz, cy, cx = stack.pop()
                if not (0 <= cz < D and 0 <= cy < H and 0 <= cx < W):
                    continue
                if visited[cz, cy, cx]:
                    continue
                visited[cz, cy, cx] = True
                labels[cz, cy, cx] = current_id

                if cz < D-1 and z_aff[cz, cy, cx]:
                    stack.append((cz+1, cy, cx))
                if cy < H-1 and y_aff[cz, cy, cx]:
                    stack.append((cz, cy+1, cx))
                if cx < W-1 and x_aff[cz, cy, cx]:
                    stack.append((cz, cy, cx+1))

        for z in range(D):
            for y in range(H):
                for x in range(W):
                    if not visited[z, y, x]:
                        dfs(z, y, x)
                        current_id += 1

        restored_instances.append(labels.astype(np.uint16))

# === Save outputs ===
os.makedirs(SAVE_DIR, exist_ok=True)

for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw.astype(np.float32))

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



# inference_affinity_3d.py
import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader
from skimage.measure import label
import h5py
from cremi_affinity_3d_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch100.pth"
CONFIG_PATH = "./output/vitmae3d/checkpoint-100000"
H5_PATH = "./data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
PATCH_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === Load full labels for ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, patch_size=PATCH_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = torch.utils.data.Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = PATCH_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# === Inference & reconstruction ===
restored_raws = []
restored_instances = []
gt_labels = []

with torch.no_grad():
    for i, (raw, _) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        restored_raws.append(raw_np)

        # Save corresponding GT label patch
        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = PATCH_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        pred = torch.sigmoid(model(raw))[0].cpu().numpy()  # [3, D, H, W]

        # === Post-process to instance segmentation ===
        z_aff = (pred[0] > 0.5).astype(np.uint8)
        y_aff = (pred[1] > 0.5).astype(np.uint8)
        x_aff = (pred[2] > 0.5).astype(np.uint8)

        D, H, W = z_aff.shape
        visited = np.zeros((D, H, W), dtype=bool)
        labels = np.zeros((D, H, W), dtype=np.int32)
        current_id = 1

        def dfs(z, y, x):
            stack = [(z, y, x)]
            while stack:
                cz, cy, cx = stack.pop()
                if not (0 <= cz < D and 0 <= cy < H and 0 <= cx < W):
                    continue
                if visited[cz, cy, cx]:
                    continue
                visited[cz, cy, cx] = True
                labels[cz, cy, cx] = current_id

                if cz < D-1 and z_aff[cz, cy, cx]:
                    stack.append((cz+1, cy, cx))
                if cy < H-1 and y_aff[cz, cy, cx]:
                    stack.append((cz, cy+1, cx))
                if cx < W-1 and x_aff[cz, cy, cx]:
                    stack.append((cz, cy, cx+1))

        for z in range(D):
            for y in range(H):
                for x in range(W):
                    if not visited[z, y, x]:
                        dfs(z, y, x)
                        current_id += 1

        restored_instances.append(labels.astype(np.uint16))

# === Save outputs ===
os.makedirs(SAVE_DIR, exist_ok=True)

for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw.astype(np.float32))

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")



# inference_mae3d.py
import os
import torch
import numpy as np
import tifffile
import matplotlib.pyplot as plt
from transformers import ViTMAEConfig
from vitmae3d import ViTMAEForPreTraining

# === 配置 ===
CHECKPOINT_PATH = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d/checkpoint-1730000"  # 模型 checkpoint 路径
TIF_IMAGE_PATH = "/home/guilin/PycharmProjects/MAE3d/data/val/FAFB_crop_hdf_2/0_0_900_1000_14.tif"                         # 输入 3D tif 图像路径
PATCH_SIZE = (16, 16, 16)
CROP_SIZE = (32, 320, 320)
MEAN = 143.510583 / 255
STD = 45.286453 / 255
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === 加载模型 ===
print("Loading model from:", CHECKPOINT_PATH)
model = ViTMAEForPreTraining.from_pretrained(CHECKPOINT_PATH)
model.config.image_size = tuple(model.config.image_size)
model.eval()
model.to(DEVICE)

# === 读取 tif 图像 ===
volume = tifffile.imread(TIF_IMAGE_PATH).astype(np.float32)  # [D, H, W]
volume = (volume / 255.0 - MEAN) / STD #归一化加标准化

# === 中心裁剪 3D patch ===
D, H, W = volume.shape
zd, yh, xw = CROP_SIZE
z0 = (D - zd) // 2
y0 = (H - yh) // 2
x0 = (W - xw) // 2
crop = volume[z0:z0+zd, y0:y0+yh, x0:x0+xw]  # [D, H, W]

# === 构建模型输入 ===
tensor_input = torch.tensor(crop, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)  # [1, 1, D, H, W]

# === 推理 ===
with torch.no_grad():
    outputs = model(pixel_values=tensor_input)
    loss = outputs.loss
    logits = outputs.logits
    mask = outputs.mask
    ids_restore = outputs.ids_restore
    print(f"Reconstruction loss: {loss.item():.4f}")

# === 原图 patchify & 构造 masked 图像 ===
patchified = model.patchify(tensor_input)  # [1, N, patch_dim]
B, N, P = patchified.shape
masked_patchified = patchified.clone()
masked_patchified[0][mask[0].bool()] = 0  # 将被 mask 的 patch 置为 0

# === 还原图像 ===
original = crop * STD + MEAN
masked_volume = model.unpatchify(masked_patchified)[0, 0].cpu().numpy() * STD + MEAN
reconstructed = model.unpatchify(logits)[0, 0].cpu().numpy() * STD + MEAN

# === 可视化中间切片 ===
slice_idx = CROP_SIZE[0] // 2
original_slice = original[slice_idx]
masked_slice = masked_volume[slice_idx]
reconstructed_slice = reconstructed[slice_idx]

plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.imshow(original_slice, cmap="gray")
plt.title("Original (Z=%d)" % slice_idx)
plt.axis("off")

plt.subplot(1, 3, 2)
plt.imshow(masked_slice, cmap="gray")
plt.title("Masked Input")
plt.axis("off")

plt.subplot(1, 3, 3)
plt.imshow(reconstructed_slice, cmap="gray")
plt.title("Reconstructed")
plt.axis("off")

plt.tight_layout()
os.makedirs("results", exist_ok=True)
plt.savefig("results/reconstruction_triplet.png")
plt.show()
print("✅ Saved: results/reconstruction_triplet.png")
