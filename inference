pip uninstall elf -y
pip install git+https://github.com/funkelab/elf.git



import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.segmentation import watershed
from skimage.filters import gaussian
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unetR import MAEUNETRSkipSegmentation
from transformers import ViTMAEConfig
import torch.nn as nn
from scipy import ndimage

# === Config ===
CHECKPOINT_PATH = "checkpoints_affinity3d/mae3d_unet_epoch300.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 143.51 / 255
STD = 45.29 / 255
THRESHOLD = 0.7

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNETRSkipSegmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=True))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff, boundary) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD +MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())


        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")

        # === Step 3: Fragmentation using watershed ===
        #edge = 1 - np.mean(pred, axis=0)  # [D, H, W]
        weight_aff = (
            2.0 * pred[0] +
            1.0 * pred[1] +
            1.0 * pred[2]
        ) / 4.0
        edge = 1 - weight_aff
        edge = gaussian(edge, sigma=1.0)
        distance = ndimage.distance_transform_edt(edge < 0.4)
        markers = label(distance > np.percentile(distance, 99)).astype(np.int32)
        fragments = watershed(edge, markers, mask=(edge < 0.5))

        # === Step 4 & 5: Connected components (simplified agglomeration) ===
        instance = label(fragments, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

        # === Save debug ===
        tifffile.imwrite(os.path.join(SAVE_DIR, f"prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"fragments_patch{i}.tif"), fragments.astype(np.uint16))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), instance)

    # === Save all patches ===
    for i, raw in enumerate(restored_raws):
        tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)
    for i, gt in enumerate(gt_labels):
        tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

    print(f"✅ Saved {len(restored_instances)} baseline instance segmentations and raw/GT to {SAVE_DIR}")
    print(f"✅ Average test loss: {np.mean(all_loss):.4f}")




import os
import torch
import tifffile
import numpy as np
import argparse
from torch.utils.data import DataLoader, Subset
import h5py
from cremi_affinity_3d_dataset import CREMIAffinity3DDataset
from mae3d_unetR import MAEUNETRSkipSegmentation
from transformers import ViTMAEConfig
import torch.nn as nn
from skimage.measure import label
from skimage.filters import gaussian
from scipy import ndimage

from elf.segmentation import compute_rag, agglomerate  # ✅ RAG-based agglomeration

# === 参数设置 ===
MERGE_THRESHOLD = 0.4  # agglomeration merge阈值
EDGE_MODE = "min"      # edge构建方式：min / mean / z_only

# === 路径配置 ===
CHECKPOINT_PATH = "checkpoints_affinity3d/mae3d_unet_epoch300.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_cremi_agglomeration"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 143.51 / 255
STD = 45.29 / 255

os.makedirs(SAVE_DIR, exist_ok=True)

# === 加载 ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === 构建 Dataset（10% C 组作为测试集）===
full_dataset = CREMIAffinity3DDataset(H5_PATH, patch_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === 加载模型 ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNETRSkipSegmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

criterion = nn.BCEWithLogitsLoss()
restored_instances = []
gt_labels = []
restored_raws = []
all_loss = []

# === 推理 + 实例恢复 ===
with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD + MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)
        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())

        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")

        # === 构建边界图 ===
        if EDGE_MODE == "min":
            edge = 1 - np.min(pred, axis=0)
        elif EDGE_MODE == "mean":
            edge = 1 - np.mean(pred, axis=0)
        elif EDGE_MODE == "z_only":
            edge = 1 - pred[0]
        else:
            raise ValueError(f"Unsupported edge_mode: {EDGE_MODE}")

        edge = gaussian(edge, sigma=1.0)

        # === watershed fragmentation ===
        distance = ndimage.distance_transform_edt(edge < MERGE_THRESHOLD)
        markers = label(distance > np.percentile(distance, 99)).astype(np.int32)
        fragments = watershed=edge < MERGE_THRESHOLD
        fragments = label(fragments)

        # === 构建 RAG + affinity-based agglomeration ===
        rag = compute_rag(fragments, number_of_labels=int(fragments.max() + 1))
        edge_weights = np.mean(pred, axis=0).astype(np.float32)  # average affinity
        instance = agglomerate(rag, edge_weights, threshold=MERGE_THRESHOLD).astype(np.uint16)

        # === 保存结果 ===
        restored_instances.append(instance)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"prob_edge_patch{i}.tif"), edge.astype(np.float32))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"fragments_patch{i}.tif"), fragments.astype(np.uint16))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), instance)

# === 保存所有 patch ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)
for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations and raw/GT to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.segmentation import watershed
from skimage.filters import gaussian
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unetR import MAEUNETRSkipSegmentation
from transformers import ViTMAEConfig
import torch.nn as nn
from scipy import ndimage

# === Config ===
CHECKPOINT_PATH = "checkpoints_affinity3d/mae3d_unet_epoch300.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d1"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 143.51 / 255
STD = 45.29 / 255
THRESHOLD = 0.7

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNETRSkipSegmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=True))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff, boundary) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD +MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())


        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        tifffile.imwrite(os.path.join(SAVE_DIR,f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))  # 不加阈值
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_y_aff_patch{i}.tif"), pred[1].astype(np.float32))  # 不加阈值
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_x_aff_patch{i}.tif"), pred[2].astype(np.float32))  # 不加阈值

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")


        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        print(f"z_aff ratio: {z_aff.sum() / z_aff.size:.4f}")
        print(f"y_aff ratio: {y_aff.sum() / y_aff.size:.4f}")
        print(f"x_aff ratio: {x_aff.sum() / x_aff.size:.4f}")


        # Save z_aff debug as uint8 for visualization
        #tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))

        # === 实例分割 ===

        conn = np.ones_like(z_aff, dtype=bool)
        conn[:-1] &= z_aff[:-1] & z_aff[1:]
        conn[:, :-1] &= y_aff[:, :-1] & y_aff[:, 1:]
        conn[:, :, :-1] &= x_aff[:, :, :-1] & x_aff[:, :, 1:]
        # === 仅基于 z+ affinity 做实例分割 ===
        # conn = np.zeros_like(z_aff, dtype=bool)
        # conn[:-1] |= z_aff[:-1]

        instance = label(conn, connectivity=1).astype(np.uint16)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), instance)
        restored_instances.append(instance)


# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")





print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")

        # === Step 3: Fragmentation using watershed ===
        edge = 1 - np.mean(pred, axis=0)  # [D, H, W]
        edge = gaussian(edge, sigma=1.0)
        distance = ndimage.distance_transform_edt(edge < 0.5)
        markers = label(distance > np.percentile(distance, 99)).astype(np.int32)
        fragments = watershed(edge, markers, mask=(edge < 0.5))

        # === Step 4 & 5: Connected components (simplified agglomeration) ===
        instance = label(fragments, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

        # === Save debug ===
        tifffile.imwrite(os.path.join(SAVE_DIR, f"prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"fragments_patch{i}.tif"), fragments.astype(np.uint16))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), instance)

# === Save all patches ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)
for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} baseline instance segmentations and raw/GT to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



# inference_affinity_3d.py
import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_affinity_3d_dataset import CREMIAffinity3DDataset
from mae3d_unetR import MAEUNETRSkipSegmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "checkpoints_affinity3d/mae3d_unet_epoch300.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d1"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 143.51 / 255
STD = 45.29 / 255
THRESHOLD = 0.7

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, patch_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNETRSkipSegmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD + MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())

        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")

        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        print(f"z_aff ratio: {z_aff.sum() / z_aff.size:.4f}")
        print(f"y_aff ratio: {y_aff.sum() / y_aff.size:.4f}")
        print(f"x_aff ratio: {x_aff.sum() / x_aff.size:.4f}")

        # === 实例分割：使用 affinity connectivity (CREMI baseline style) ===
        conn = np.ones_like(z_aff, dtype=bool)
        conn[:-1] &= z_aff[:-1] & z_aff[1:]
        conn[:, :-1] &= y_aff[:, :-1] & y_aff[:, 1:]
        conn[:, :, :-1] &= x_aff[:, :, :-1] & x_aff[:, :, 1:]

        instance = label(conn, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

        # === 保存中间图像 ===
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_y_aff_patch{i}.tif"), pred[1].astype(np.float32))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_x_aff_patch{i}.tif"), pred[2].astype(np.float32))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), instance)

# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")




import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unetR import MAEUNETRSkipSegmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "checkpoints_affinity3d/mae3d_unet_epoch300.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d1"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 143.51 / 255
STD = 45.29 / 255
THRESHOLD = 0.7

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNETRSkipSegmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=True))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff, boundary) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD +MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())


        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        tifffile.imwrite(os.path.join(SAVE_DIR,f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))  # 不加阈值
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_y_aff_patch{i}.tif"), pred[1].astype(np.float32))  # 不加阈值
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_x_aff_patch{i}.tif"), pred[2].astype(np.float32))  # 不加阈值

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")


        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        print(f"z_aff ratio: {z_aff.sum() / z_aff.size:.4f}")
        print(f"y_aff ratio: {y_aff.sum() / y_aff.size:.4f}")
        print(f"x_aff ratio: {x_aff.sum() / x_aff.size:.4f}")


        # Save z_aff debug as uint8 for visualization
        #tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))

        # === 实例分割 ===

        conn = np.ones_like(z_aff, dtype=bool)
        conn[:-1] &= z_aff[:-1] & z_aff[1:]
        conn[:, :-1] &= y_aff[:, :-1] & y_aff[:, 1:]
        conn[:, :, :-1] &= x_aff[:, :, :-1] & x_aff[:, :, 1:]
        # === 仅基于 z+ affinity 做实例分割 ===
        # conn = np.zeros_like(z_aff, dtype=bool)
        # conn[:-1] |= z_aff[:-1]

        instance = label(conn, connectivity=1).astype(np.uint16)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), instance)
        restored_instances.append(instance)


# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")




conn = np.ones_like(z_aff, dtype=bool)
conn[:-1] &= z_aff[:-1] & z_aff[1:]
conn[:, :-1] &= y_aff[:, :-1] & y_aff[:, 1:]
conn[:, :, :-1] &= x_aff[:, :, :-1] & x_aff[:, :, 1:]


import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch180.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 160, 160)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 127.91 / 255
STD = 28 / 255
THRESHOLD = 0.7  # 可调整

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load ground truth neuron_ids volume ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset: 使用 sample C 的后 10% patch 作为测试集 ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model and weights ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

criterion = nn.BCEWithLogitsLoss()

restored_instances = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff, boundary) in enumerate(test_loader):
        # === 恢复原图像（反标准化） ===
        raw_tensor = raw[0, 0]
        raw_np = raw_tensor.detach().cpu().numpy() if isinstance(raw_tensor, torch.Tensor) else raw_tensor
        raw_restore = (raw_np * STD + MEAN) * 255.0
        raw_uint8 = raw_restore.clip(0, 255).astype(np.uint8)

        # === 提取对应 GT 标签区域 ===
        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        # === 推理 & loss ===
        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())

        pred = torch.sigmoid(output)[0].cpu().numpy()
        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        # === 保存调试图 ===
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw_uint8)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

        # === 仅基于 z+ affinity 做实例分割 ===
        conn = np.zeros_like(z_aff, dtype=bool)
        conn[:-1] |= z_aff[:-1]
        instance = label(conn, connectivity=1).astype(np.uint16)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), instance)
        restored_instances.append(instance)

print(f"✅ Saved {len(restored_instances)} instance segmentations and results to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch180.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 160, 160)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 127.91 / 255
STD = 28 / 255
THRESHOLD = 0.7

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load ground truth neuron_ids volume ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

criterion = nn.BCEWithLogitsLoss()

restored_instances = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff, boundary) in enumerate(test_loader):
        raw_tensor = raw[0, 0]
        raw_np = raw_tensor.detach().cpu().numpy() if isinstance(raw_tensor, torch.Tensor) else raw_tensor
        raw_restore = (raw_np * STD + MEAN) * 255.0
        raw_uint8 = raw_restore.clip(0, 255).astype(np.uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())

        pred = torch.sigmoid(output)[0].cpu().numpy()
        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        # === 保存调试图 ===
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))
        tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw_uint8)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

        # === 使用 z+y+x affinity 构建实例图 ===
        conn = np.zeros_like(z_aff, dtype=bool)
        conn[:-1] |= z_aff[:-1]
        conn[:, :-1] |= y_aff[:, :-1]
        conn[:, :, :-1] |= x_aff[:, :, :-1]
        instance = label(conn, connectivity=1).astype(np.uint16)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), instance)
        restored_instances.append(instance)

print(f"✅ Saved {len(restored_instances)} instance segmentations (z+y+x affinity) to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")


import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d1/mae3d_unet_epoch100.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 160, 160)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 127.91 / 255
STD = 28 / 255
THRESHOLD = 0.7

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=True))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff, boundary) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD +MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())


        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        tifffile.imwrite(os.path.join(SAVE_DIR,f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))  # 不加阈值

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")


        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        print(f"z_aff ratio: {z_aff.sum() / z_aff.size:.4f}")
        print(f"y_aff ratio: {y_aff.sum() / y_aff.size:.4f}")
        print(f"x_aff ratio: {x_aff.sum() / x_aff.size:.4f}")


        # Save z_aff debug as uint8 for visualization
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))

        # === Connected component labeling ===
        aff_mask = np.zeros_like(z_aff, dtype=bool)
        aff_mask[:-1] &= z_aff[:-1]
        aff_mask[:, :-1] &= y_aff[:, :-1]
        aff_mask[:, :, :-1] &= x_aff[:, :, :-1]

        instance = label(aff_mask, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")




import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d1/mae3d_unet_epoch70.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 127.91 / 255
STD = 28 / 255
THRESHOLD = 0.7

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=True))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD +MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())


        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        tifffile.imwrite(os.path.join(SAVE_DIR,f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))  # 不加阈值

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")


        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        print(f"z_aff ratio: {z_aff.sum() / z_aff.size:.4f}")
        print(f"y_aff ratio: {y_aff.sum() / y_aff.size:.4f}")
        print(f"x_aff ratio: {x_aff.sum() / x_aff.size:.4f}")


        # Save z_aff debug as uint8 for visualization
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))

        # === Connected component labeling ===
        aff_mask = np.zeros_like(z_aff, dtype=bool)
        aff_mask[:-1] &= z_aff[:-1]
        aff_mask[:, :-1] &= y_aff[:, :-1]
        aff_mask[:, :, :-1] &= x_aff[:, :, :-1]

        instance = label(aff_mask, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch180.pth"
CONFIG_PATH = "./output/vitmae3d"
H5_PATH = "./segementation_data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MEAN = 127.91 / 255
STD = 28 / 255
THRESHOLD = 0.9

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=True))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = ((raw_np * STD +MEAN) * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())


        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        tifffile.imwrite(os.path.join(SAVE_DIR,f"debug_prob_z_aff_patch{i}.tif"), pred[0].astype(np.float32))  # 不加阈值

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")


        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        print(f"z_aff ratio: {z_aff.sum() / z_aff.size:.4f}")
        print(f"y_aff ratio: {y_aff.sum() / y_aff.size:.4f}")
        print(f"x_aff ratio: {x_aff.sum() / x_aff.size:.4f}")


        # Save z_aff debug as uint8 for visualization
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))

        # === Connected component labeling ===
        aff_mask = np.ones_like(z_aff, dtype=bool)
        aff_mask[:-1] &= z_aff[:-1]
        aff_mask[:, :-1] &= y_aff[:, :-1]
        aff_mask[:, :, :-1] &= x_aff[:, :, :-1]

        instance = label(aff_mask, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader, Subset
from skimage.measure import label
import h5py
from cremi_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch100.pth"
CONFIG_PATH = "./output/vitmae3d/checkpoint-100000"
H5_PATH = "./data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
THRESHOLD = 0.5

os.makedirs(SAVE_DIR, exist_ok=True)

# === Load full ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, crop_size=CROP_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = CROP_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

criterion = nn.BCEWithLogitsLoss()

# === Inference ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        raw_uint8 = (raw_np * 255).clip(0, 255).astype(np.uint8)
        restored_raws.append(raw_uint8)

        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = CROP_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())

        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]
        z_aff = (pred[0] > THRESHOLD)
        y_aff = (pred[1] > THRESHOLD)
        x_aff = (pred[2] > THRESHOLD)

        # Save z_aff debug as uint8 for visualization
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff.astype(np.uint8))

        # === Connected component labeling ===
        aff_mask = np.ones_like(z_aff, dtype=bool)
        aff_mask[:-1] &= z_aff[:-1]
        aff_mask[:, :-1] &= y_aff[:, :-1]
        aff_mask[:, :, :-1] &= x_aff[:, :, :-1]

        instance = label(aff_mask, connectivity=1).astype(np.uint16)
        restored_instances.append(instance)

# === Save results ===
for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw)

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



# inference_affinity_3d.py
import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader
from skimage.measure import label
import h5py
from cremi_affinity_3d_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig
import torch.nn as nn

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch100.pth"
CONFIG_PATH = "./output/vitmae3d/checkpoint-100000"
H5_PATH = "./data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
PATCH_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
THRESHOLD = 0.5

# === Load full labels for ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, patch_size=PATCH_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = torch.utils.data.Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = PATCH_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# === Loss for reporting ===
criterion = nn.BCEWithLogitsLoss()

# === Inference & reconstruction ===
restored_raws = []
restored_instances = []
gt_labels = []
all_loss = []

with torch.no_grad():
    for i, (raw, target_aff) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        restored_raws.append(raw_np)

        # Save corresponding GT label patch
        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = PATCH_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        target_aff = target_aff.to(DEVICE)

        output = model(raw)
        loss = criterion(output, target_aff)
        all_loss.append(loss.item())

        pred = torch.sigmoid(output)[0].cpu().numpy()  # [3, D, H, W]

        print(f"[Patch {i}] pred max: {pred.max():.4f}, mean: {pred.mean():.4f}, loss: {loss.item():.4f}")

        # === Save z_aff debug image ===
        z_aff = (pred[0] > THRESHOLD).astype(np.uint8)
        tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff)

        y_aff = (pred[1] > THRESHOLD).astype(np.uint8)
        x_aff = (pred[2] > THRESHOLD).astype(np.uint8)

        D, H, W = z_aff.shape
        visited = np.zeros((D, H, W), dtype=bool)
        labels = np.zeros((D, H, W), dtype=np.int32)
        current_id = 1

        def dfs(z, y, x):
            stack = [(z, y, x)]
            while stack:
                cz, cy, cx = stack.pop()
                if not (0 <= cz < D and 0 <= cy < H and 0 <= cx < W):
                    continue
                if visited[cz, cy, cx]:
                    continue
                visited[cz, cy, cx] = True
                labels[cz, cy, cx] = current_id

                if cz < D-1 and z_aff[cz, cy, cx]:
                    stack.append((cz+1, cy, cx))
                if cy < H-1 and y_aff[cz, cy, cx]:
                    stack.append((cz, cy+1, cx))
                if cx < W-1 and x_aff[cz, cy, cx]:
                    stack.append((cz, cy, cx+1))

        for z in range(D):
            for y in range(H):
                for x in range(W):
                    if not visited[z, y, x]:
                        dfs(z, y, x)
                        current_id += 1

        restored_instances.append(labels.astype(np.uint16))

# === Save outputs ===
os.makedirs(SAVE_DIR, exist_ok=True)

for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw.astype(np.float32))

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")
print(f"✅ Average test loss: {np.mean(all_loss):.4f}")



# inference_affinity_3d.py
import os
import torch
import tifffile
import numpy as np
from torch.utils.data import DataLoader
from skimage.measure import label
import h5py
from cremi_affinity_3d_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig

# === Config ===
CHECKPOINT_PATH = "./checkpoints_affinity3d/mae3d_unet_epoch100.pth"
CONFIG_PATH = "./output/vitmae3d/checkpoint-100000"
H5_PATH = "./data/sample_C_20160501.hdf"
SAVE_DIR = "./results_affinity3d"
PATCH_SIZE = (32, 320, 320)
BATCH_SIZE = 1
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === Load full labels for ground truth neuron_ids ===
with h5py.File(H5_PATH, "r") as f:
    full_gt_labels = f["volumes/labels/neuron_ids"][()]

# === Dataset (10% C as test set) ===
full_dataset = CREMIAffinity3DDataset(H5_PATH, patch_size=PATCH_SIZE)
total_len = len(full_dataset)
val_len = int(total_len * 0.1)
test_indices = list(range(total_len - val_len, total_len))
test_dataset = torch.utils.data.Subset(full_dataset, test_indices)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)

# === Load model ===
config = ViTMAEConfig.from_pretrained(CONFIG_PATH)
config.image_size = PATCH_SIZE
config.mask_ratio = 0.0
model = MAEUNet2Segmentation(CONFIG_PATH, config, num_classes=3).to(DEVICE)
model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
model.eval()

# === Inference & reconstruction ===
restored_raws = []
restored_instances = []
gt_labels = []

with torch.no_grad():
    for i, (raw, _) in enumerate(test_loader):
        raw_np = raw[0, 0].numpy()
        restored_raws.append(raw_np)

        # Save corresponding GT label patch
        z, y, x = full_dataset.starts[test_indices[i]]
        dz, dy, dx = PATCH_SIZE
        gt = full_gt_labels[z:z+dz, y:y+dy, x:x+dx].astype(np.uint16)
        gt_labels.append(gt)

        raw = raw.to(DEVICE)
        pred = torch.sigmoid(model(raw))[0].cpu().numpy()  # [3, D, H, W]

        # === Post-process to instance segmentation ===
        z_aff = (pred[0] > 0.5).astype(np.uint8)
        y_aff = (pred[1] > 0.5).astype(np.uint8)
        x_aff = (pred[2] > 0.5).astype(np.uint8)

        D, H, W = z_aff.shape
        visited = np.zeros((D, H, W), dtype=bool)
        labels = np.zeros((D, H, W), dtype=np.int32)
        current_id = 1

        def dfs(z, y, x):
            stack = [(z, y, x)]
            while stack:
                cz, cy, cx = stack.pop()
                if not (0 <= cz < D and 0 <= cy < H and 0 <= cx < W):
                    continue
                if visited[cz, cy, cx]:
                    continue
                visited[cz, cy, cx] = True
                labels[cz, cy, cx] = current_id

                if cz < D-1 and z_aff[cz, cy, cx]:
                    stack.append((cz+1, cy, cx))
                if cy < H-1 and y_aff[cz, cy, cx]:
                    stack.append((cz, cy+1, cx))
                if cx < W-1 and x_aff[cz, cy, cx]:
                    stack.append((cz, cy, cx+1))

        for z in range(D):
            for y in range(H):
                for x in range(W):
                    if not visited[z, y, x]:
                        dfs(z, y, x)
                        current_id += 1

        restored_instances.append(labels.astype(np.uint16))

# === Save outputs ===
os.makedirs(SAVE_DIR, exist_ok=True)

for i, raw in enumerate(restored_raws):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw.astype(np.float32))

for i, inst in enumerate(restored_instances):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"instance_patch{i}.tif"), inst)

for i, gt in enumerate(gt_labels):
    tifffile.imwrite(os.path.join(SAVE_DIR, f"gt_patch{i}.tif"), gt)

print(f"✅ Saved {len(restored_instances)} instance segmentations, raw patches, and GT patches to {SAVE_DIR}")



# inference_mae3d.py
import os
import torch
import numpy as np
import tifffile
import matplotlib.pyplot as plt
from transformers import ViTMAEConfig
from vitmae3d import ViTMAEForPreTraining

# === 配置 ===
CHECKPOINT_PATH = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d/checkpoint-1730000"  # 模型 checkpoint 路径
TIF_IMAGE_PATH = "/home/guilin/PycharmProjects/MAE3d/data/val/FAFB_crop_hdf_2/0_0_900_1000_14.tif"                         # 输入 3D tif 图像路径
PATCH_SIZE = (16, 16, 16)
CROP_SIZE = (32, 320, 320)
MEAN = 143.510583 / 255
STD = 45.286453 / 255
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === 加载模型 ===
print("Loading model from:", CHECKPOINT_PATH)
model = ViTMAEForPreTraining.from_pretrained(CHECKPOINT_PATH)
model.config.image_size = tuple(model.config.image_size)
model.eval()
model.to(DEVICE)

# === 读取 tif 图像 ===
volume = tifffile.imread(TIF_IMAGE_PATH).astype(np.float32)  # [D, H, W]
volume = (volume / 255.0 - MEAN) / STD #归一化加标准化

# === 中心裁剪 3D patch ===
D, H, W = volume.shape
zd, yh, xw = CROP_SIZE
z0 = (D - zd) // 2
y0 = (H - yh) // 2
x0 = (W - xw) // 2
crop = volume[z0:z0+zd, y0:y0+yh, x0:x0+xw]  # [D, H, W]

# === 构建模型输入 ===
tensor_input = torch.tensor(crop, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)  # [1, 1, D, H, W]

# === 推理 ===
with torch.no_grad():
    outputs = model(pixel_values=tensor_input)
    loss = outputs.loss
    logits = outputs.logits
    mask = outputs.mask
    ids_restore = outputs.ids_restore
    print(f"Reconstruction loss: {loss.item():.4f}")

# === 原图 patchify & 构造 masked 图像 ===
patchified = model.patchify(tensor_input)  # [1, N, patch_dim]
B, N, P = patchified.shape
masked_patchified = patchified.clone()
masked_patchified[0][mask[0].bool()] = 0  # 将被 mask 的 patch 置为 0

# === 还原图像 ===
original = crop * STD + MEAN
masked_volume = model.unpatchify(masked_patchified)[0, 0].cpu().numpy() * STD + MEAN
reconstructed = model.unpatchify(logits)[0, 0].cpu().numpy() * STD + MEAN

# === 可视化中间切片 ===
slice_idx = CROP_SIZE[0] // 2
original_slice = original[slice_idx]
masked_slice = masked_volume[slice_idx]
reconstructed_slice = reconstructed[slice_idx]

plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.imshow(original_slice, cmap="gray")
plt.title("Original (Z=%d)" % slice_idx)
plt.axis("off")

plt.subplot(1, 3, 2)
plt.imshow(masked_slice, cmap="gray")
plt.title("Masked Input")
plt.axis("off")

plt.subplot(1, 3, 3)
plt.imshow(reconstructed_slice, cmap="gray")
plt.title("Reconstructed")
plt.axis("off")

plt.tight_layout()
os.makedirs("results", exist_ok=True)
plt.savefig("results/reconstruction_triplet.png")
plt.show()
print("✅ Saved: results/reconstruction_triplet.png")
