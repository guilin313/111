# inference_mae3d.py
import os
import torch
import numpy as np
import tifffile
import matplotlib.pyplot as plt
from transformers import ViTMAEConfig
from vitmae3d import ViTMAEForPreTraining

# === 配置 ===
CHECKPOINT_PATH = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d/checkpoint-1670000"  # 模型 checkpoint 路径
TIF_IMAGE_PATH = "/home/guilin/PycharmProjects/MAE3d/data/val/FAFB_crop_hdf_2/0_0_900_1000_14.tif"                         # 输入 3D tif 图像路径
PATCH_SIZE = (16, 16, 16)
CROP_SIZE = (32, 320, 320)
MEAN = 143.510583 / 255
STD = 45.286453 / 255
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === 加载模型 ===
print("Loading model from:", CHECKPOINT_PATH)
config = ViTMAEForPreTraining.from_pretrained(CHECKPOINT_PATH)
config.image_size = tuple(config.image_size)
model = ViTMAEForPreTraining(config)
model.eval()
model.to(DEVICE)

# === 读取 tif 图像 ===
volume = tifffile.imread(TIF_IMAGE_PATH).astype(np.float32)  # [D, H, W]
volume = (volume / 255.0 - MEAN) / STD

# === 中心裁剪 3D patch ===
D, H, W = volume.shape
zd, yh, xw = CROP_SIZE
z0 = (D - zd) // 2
y0 = (H - yh) // 2
x0 = (W - xw) // 2
crop = volume[z0:z0+zd, y0:y0+yh, x0:x0+xw]  # [D, H, W]

# === 构建模型输入 ===
tensor_input = torch.tensor(crop, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)  # [1, 1, D, H, W]

# === 推理 ===
with torch.no_grad():
    outputs = model(pixel_values=tensor_input)
    loss = outputs.loss
    logits = outputs.logits
    mask = outputs.mask
    ids_restore = outputs.ids_restore
    print(f"Reconstruction loss: {loss.item():.4f}")

# === 原图 patchify & 构造 masked 图像 ===
patchified = model.patchify(tensor_input)  # [1, N, patch_dim]
B, N, P = patchified.shape
masked_patchified = patchified.clone()
masked_patchified[0][mask[0].bool()] = 0  # 将被 mask 的 patch 置为 0

# === 还原图像 ===
original = crop * STD + MEAN
masked_volume = model.unpatchify(masked_patchified)[0, 0].cpu().numpy() * STD + MEAN
reconstructed = model.unpatchify(logits)[0, 0].cpu().numpy() * STD + MEAN

# === 可视化中间切片 ===
slice_idx = CROP_SIZE[0] // 2
original_slice = original[slice_idx]
masked_slice = masked_volume[slice_idx]
reconstructed_slice = reconstructed[slice_idx]

plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.imshow(original_slice, cmap="gray")
plt.title("Original (Z=%d)" % slice_idx)
plt.axis("off")

plt.subplot(1, 3, 2)
plt.imshow(masked_slice, cmap="gray")
plt.title("Masked Input")
plt.axis("off")

plt.subplot(1, 3, 3)
plt.imshow(reconstructed_slice, cmap="gray")
plt.title("Reconstructed")
plt.axis("off")

plt.tight_layout()
os.makedirs("results", exist_ok=True)
plt.savefig("results/reconstruction_triplet.png")
plt.show()
print("✅ Saved: results/reconstruction_triplet.png")
