Epoch 1/300 [Train]:   0%|          | 0/93 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 104, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unetR.py", line 48, in forward
    output = self.unetr(x, z12, [z3, z6, z9, z12])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: UNETR.forward() takes 2 positional arguments but 4 were given

Process finished with exit code 1



Epoch 1/300 [Train]:   0%|          | 0/93 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_continue.py", line 119, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unetR.py", line 48, in forward
    output = self.unetr(x, z12, [z3, z6, z9, z12])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: UNETR.forward() takes 2 positional arguments but 4 were given

Process finished with exit code 1



Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inspect_encoder.py", line 44, in <module>
    output = model(dummy_input)
             ^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 94, in forward
    out = self.encoder(pixel_values=x, output_hidden_states=True, return_dict=True)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 823, in forward
    embedding_output, mask, ids_restore = self.embeddings(
                                          ^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 315, in forward
    embeddings = self.patch_embeddings(pixel_values, interpolate_pos_encoding=interpolate_pos_encoding)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 363, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.




/home/guilin/PycharmProjects/MAE3d/inspect_encoder.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(checkpoint_path, map_location=DEVICE)
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inspect_encoder.py", line 24, in <module>
    model.load_state_dict(state_dict["model_state_dict"])
                          ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
KeyError: 'model_state_dict'

Process finished with exit code 1


Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 104, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 105, in forward
    return self.decoder(main, [skip1, skip2, skip3, skip4])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 53, in forward
    return self.out(x)
           ^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 725, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 720, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [3, 32, 1, 1, 1], expected input[2, 64, 32, 320, 320] to have 32 channels, but got 64 channels instead

Process finished with exit code 1



Epoch 1/300 [Train]:   0%|          | 0/93 [00:00<?, ?it/s]Total params: 108903715, Trainable: 33953443
Epoch 1/300 [Train]:   0%|          | 0/93 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 104, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 104, in forward
    return self.decoder(main, [skip1, skip2, skip3, skip4])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 38, in forward
    x = torch.cat([x, skips[3]], dim=1)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 2 for tensor number 1 in the list.

Process finished with exit code 1



x = self.up1(x)
x = torch.cat([x, F.interpolate(skips[0], size=x.shape[2:], mode="trilinear", align_corners=False)], dim=1)
x = self.conv1(x)

x = self.up2(x)
x = torch.cat([x, F.interpolate(skips[1], size=x.shape[2:], mode="trilinear", align_corners=False)], dim=1)
x = self.conv2(x)

x = self.up3(x)
x = torch.cat([x, F.interpolate(skips[2], size=x.shape[2:], mode="trilinear", align_corners=False)], dim=1)
x = self.conv3(x)


Epoch 1/300 [Train]:   0%|          | 0/93 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 104, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 124, in forward
    return self.decoder(main, [skip1, skip2, skip3])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 40, in forward
    x = torch.cat([x, skips[0]], dim=1)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 2 for tensor number 1 in the list.

Process finished with exit code 1


/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py 
yes
Total params: 108713155, Trainable: 33762883
Epoch 1/300 [Train]:   0%|          | 0/93 [00:00<?, ?it/s]x_embed = self.encoder.embeddings(x)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
x_embed = blk(x_embed)‰∏∫tupleÔºåËΩ¨‰∏∫tensor
Epoch 1/300 [Train]:   0%|          | 0/93 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 104, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 124, in forward
    return self.decoder(main, [skip1, skip2, skip3])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 40, in forward
    x = torch.cat([x, skips[0]], dim=1)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 16 for tensor number 1 in the list.

Process finished with exit code 1



Total params: 108713155, Trainable: 33762883
Epoch 1/300 [Train]:   0%|          | 0/93 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 104, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 96, in forward
    x_embed = blk(x_embed)
              ^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 611, in forward
    self.layernorm_before(hidden_states),  # in ViTMAE, layernorm is applied before self-attention
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/normalization.py", line 217, in forward
    return F.layer_norm(
           ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/functional.py", line 2900, in layer_norm
    return torch.layer_norm(
           ^^^^^^^^^^^^^^^^^
TypeError: layer_norm(): argument 'input' (position 1) must be Tensor, not tuple

Process finished with exit code 1



Some weights of ViTMAEForPreTraining were not initialized from the model checkpoint at /home/guilin/PycharmProjects/MAE3d/output/vitmae3d and are newly initialized because the shapes did not match:
- decoder.decoder_pos_embed: found shape torch.Size([1, 801, 384]) in the checkpoint and torch.Size([1, 201, 384]) in the model instantiated
- vit.embeddings.position_embeddings: found shape torch.Size([1, 801, 768]) in the checkpoint and torch.Size([1, 201, 768]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1/300 [Train]:   0%|          | 0/372 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 101, in <module>
    loss = criterion(outputs, targets) * weight
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 46, in forward
    return (focal_loss * self.channel_weights).mean()
            ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!


[Patch 0] pred max: 0.8334, mean: 0.7179, loss: 0.3466
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 1] pred max: 0.8334, mean: 0.7179, loss: 0.3445
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 2] pred max: 0.8334, mean: 0.7179, loss: 0.3521
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 3] pred max: 0.8334, mean: 0.7179, loss: 0.3565
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 4] pred max: 0.8334, mean: 0.7179, loss: 0.3605
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 5] pred max: 0.8334, mean: 0.7179, loss: 0.3745
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 6] pred max: 0.8334, mean: 0.7179, loss: 0.3657
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 7] pred max: 0.8334, mean: 0.7179, loss: 0.3394
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 8] pred max: 0.8334, mean: 0.7179, loss: 0.3258
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 9] pred max: 0.8334, mean: 0.7179, loss: 0.3635
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 10] pred max: 0.8334, mean: 0.7179, loss: 0.3663
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 11] pred max: 0.8334, mean: 0.7179, loss: 0.3601
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 12] pred max: 0.8334, mean: 0.7179, loss: 0.3598
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 13] pred max: 0.8334, mean: 0.7179, loss: 0.3698
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 14] pred max: 0.8334, mean: 0.7179, loss: 0.3592
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 15] pred max: 0.8334, mean: 0.7179, loss: 0.3690
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 16] pred max: 0.8334, mean: 0.7179, loss: 0.3647
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 17] pred max: 0.8334, mean: 0.7179, loss: 0.3643
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 18] pred max: 0.8334, mean: 0.7179, loss: 0.3417
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 19] pred max: 0.8334, mean: 0.7179, loss: 0.3303
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 20] pred max: 0.8334, mean: 0.7179, loss: 0.3556
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 21] pred max: 0.8334, mean: 0.7179, loss: 0.3673
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 22] pred max: 0.8334, mean: 0.7179, loss: 0.3564
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 23] pred max: 0.8334, mean: 0.7179, loss: 0.3673
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 24] pred max: 0.8334, mean: 0.7179, loss: 0.3614
z_aff ratio: 0.9688
y_aff ratio: 0.9938
x_aff ratio: 0.9938
‚úÖ Saved 25 instance segmentations, raw patches, and GT patches to ./results_affinity3d1
‚úÖ Average test loss: 0.3569


[Patch 0] pred max: 0.8334, mean: 0.7179, loss: 0.3466
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 1] pred max: 0.8334, mean: 0.7179, loss: 0.3445
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 2] pred max: 0.8334, mean: 0.7179, loss: 0.3521
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 3] pred max: 0.8334, mean: 0.7179, loss: 0.3565
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 4] pred max: 0.8334, mean: 0.7179, loss: 0.3605
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 5] pred max: 0.8334, mean: 0.7179, loss: 0.3745
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 6] pred max: 0.8334, mean: 0.7179, loss: 0.3657
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 7] pred max: 0.8334, mean: 0.7179, loss: 0.3394
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 8] pred max: 0.8334, mean: 0.7179, loss: 0.3258
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 9] pred max: 0.8334, mean: 0.7179, loss: 0.3635
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 10] pred max: 0.8334, mean: 0.7179, loss: 0.3663
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 11] pred max: 0.8334, mean: 0.7179, loss: 0.3601
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 12] pred max: 0.8334, mean: 0.7179, loss: 0.3598
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 13] pred max: 0.8334, mean: 0.7179, loss: 0.3698
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 14] pred max: 0.8334, mean: 0.7179, loss: 0.3592
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 15] pred max: 0.8334, mean: 0.7179, loss: 0.3690
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 16] pred max: 0.8334, mean: 0.7179, loss: 0.3647
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 17] pred max: 0.8334, mean: 0.7179, loss: 0.3643
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 18] pred max: 0.8334, mean: 0.7179, loss: 0.3417
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 19] pred max: 0.8334, mean: 0.7179, loss: 0.3303
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 20] pred max: 0.8334, mean: 0.7179, loss: 0.3556
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 21] pred max: 0.8334, mean: 0.7179, loss: 0.3673
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 22] pred max: 0.8334, mean: 0.7179, loss: 0.3564
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 23] pred max: 0.8334, mean: 0.7179, loss: 0.3673
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
[Patch 24] pred max: 0.8334, mean: 0.7179, loss: 0.3614
z_aff ratio: 0.0000
y_aff ratio: 0.9938
x_aff ratio: 0.9938
‚úÖ Saved 25 instance segmentations, raw patches, and GT patches to ./results_affinity3d1
‚úÖ Average test loss: 0.3569



/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py 
yes
Some weights of ViTMAEForPreTraining were not initialized from the model checkpoint at /home/guilin/PycharmProjects/MAE3d/output/vitmae3d and are newly initialized because the shapes did not match:
- decoder.decoder_pos_embed: found shape torch.Size([1, 801, 384]) in the checkpoint and torch.Size([1, 201, 384]) in the model instantiated
- vit.embeddings.position_embeddings: found shape torch.Size([1, 801, 768]) in the checkpoint and torch.Size([1, 201, 768]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1/300 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 180/372 [00:25<00:26,  7.16it/s]



/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py 
yes
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 60, in <module>
    model = MAEUNet2Segmentation(CHECKPOINT, config, num_classes=NUM_CLASSES).to(DEVICE)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 48, in __init__
    self.mae = ViTMAEForPreTraining.from_pretrained(pretrained_path, config=config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/modeling_utils.py", line 272, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4480, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4930, in _load_pretrained_model
    model_to_load.load_state_dict(state_dict, strict=False, assign=assign_params)
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ViTMAEForPreTraining:
	size mismatch for vit.embeddings.position_embeddings: copying a param with shape torch.Size([1, 801, 768]) from checkpoint, the shape in current model is torch.Size([1, 201, 768]).
	size mismatch for decoder.decoder_pos_embed: copying a param with shape torch.Size([1, 801, 384]) from checkpoint, the shape in current model is torch.Size([1, 201, 384]).

Process finished with exit code 1



/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/cremi_dataset.py 
üìä ÊØîËæÉÂ§öÁßç patch size ‰∏ãÁöÑ‰∫≤ÂíåÂõæËøûÊé•ÊØî‰æã (sample_C_20160501.hdf, ÊØèÁßçÂâç 50 ‰∏™ patch)...

üß© Patch size: (32, 320, 320)
  ‚ûú ÊñπÂêë z+: ËøûÊé•ÊØî‰æã = 0.7930 (129927568/163840000)
  ‚ûú ÊñπÂêë y+: ËøûÊé•ÊØî‰æã = 0.9807 (160676523/163840000)
  ‚ûú ÊñπÂêë x+: ËøûÊé•ÊØî‰æã = 0.9823 (160944973/163840000)
------------------------------------------------------------
üß© Patch size: (32, 160, 160)
  ‚ûú ÊñπÂêë z+: ËøûÊé•ÊØî‰æã = 0.7656 (31358967/40960000)
  ‚ûú ÊñπÂêë y+: ËøûÊé•ÊØî‰æã = 0.9770 (40016375/40960000)
  ‚ûú ÊñπÂêë x+: ËøûÊé•ÊØî‰æã = 0.9792 (40108912/40960000)
------------------------------------------------------------
üß© Patch size: (32, 96, 96)
  ‚ûú ÊñπÂêë z+: ËøûÊé•ÊØî‰æã = 0.7688 (11336733/14745600)
  ‚ûú ÊñπÂêë y+: ËøûÊé•ÊØî‰æã = 0.9735 (14354359/14745600)
  ‚ûú ÊñπÂêë x+: ËøûÊé•ÊØî‰æã = 0.9750 (14376458/14745600)
------------------------------------------------------------
üß© Patch size: (32, 64, 64)
  ‚ûú ÊñπÂêë z+: ËøûÊé•ÊØî‰æã = 0.7740 (5072734/6553600)
  ‚ûú ÊñπÂêë y+: ËøûÊé•ÊØî‰æã = 0.9691 (6350900/6553600)
  ‚ûú ÊñπÂêë x+: ËøûÊé•ÊØî‰æã = 0.9696 (6354457/6553600)
------------------------------------------------------------
üß© Patch size: (64, 160, 160)
  ‚ûú ÊñπÂêë z+: ËøûÊé•ÊØî‰æã = 0.8156 (66813111/81920000)
  ‚ûú ÊñπÂêë y+: ËøûÊé•ÊØî‰æã = 0.9776 (80088706/81920000)
  ‚ûú ÊñπÂêë x+: ËøûÊé•ÊØî‰æã = 0.9794 (80235413/81920000)
------------------------------------------------------------

Process finished with exit code 0



/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/cremi_dataset.py 
üìä Ê≠£Âú®ÁªüËÆ° sample_C_20160501.hdf ‰∏≠Ââç 64 ‰∏™ patch ÁöÑ‰∫≤ÂíåÂõæËøûÊé•ÊØî‰æã...
‚û°Ô∏è ÊñπÂêë z+: ËøûÊé•ÊØî‰æã = 0.7977 (167292814/209715200)
‚û°Ô∏è ÊñπÂêë y+: ËøûÊé•ÊØî‰æã = 0.9802 (205566076/209715200)
‚û°Ô∏è ÊñπÂêë x+: ËøûÊé•ÊØî‰æã = 0.9820 (205949488/209715200)

Process finished with exit code 0


/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py 
yes
[Patch 0] pred max: 0.8565, mean: 0.7426, loss: 0.3449
z_aff ratio: 0.0000
y_aff ratio: 0.0000
x_aff ratio: 0.0000
[Patch 1] pred max: 0.8575, mean: 0.7711, loss: 0.2875
z_aff ratio: 0.0000
y_aff ratio: 0.0000
x_aff ratio: 0.0000
[Patch 2] pred max: 0.8533, mean: 0.7607, loss: 0.3135
z_aff ratio: 0.0000
y_aff ratio: 0.0000
x_aff ratio: 0.0000
[Patch 3] pred max: 0.8531, mean: 0.7624, loss: 0.3038
z_aff ratio: 0.0000
y_aff ratio: 0.0000
x_aff ratio: 0.0000
[Patch 4] pred max: 0.8581, mean: 0.7507, loss: 0.3274
z_aff ratio: 0.0000
y_aff ratio: 0.0000
x_aff ratio: 0.0000
[Patch 5] pred max: 0.8580, mean: 0.7524, loss: 0.3255
z_aff ratio: 0.0000
y_aff ratio: 0.0000
x_aff ratio: 0.0000
‚úÖ Saved 6 instance segmentations, raw patches, and GT patches to ./results_affinity3d
‚úÖ Average test loss: 0.3171



raw_np = raw[0, 0].detach().cpu().numpy() if isinstance(raw, torch.Tensor) else raw[0, 0]



Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py", line 105, in <module>
    raw_np = raw_tensor.detach().cpu().numpy()  # ËΩ¨Êàê numpy
             ^^^^^^^^^^^^^^^^^
AttributeError: 'numpy.ndarray' object has no attribute 'detach'

Process finished with exit code 1


# === ËøòÂéüÂõæÂÉèÔºàÂèçÊ†áÂáÜÂåñÔºâ
raw_tensor = raw[0, 0]  # Tensor Á±ªÂûã [1, D, H, W]
raw_np = raw_tensor.detach().cpu().numpy()  # ËΩ¨Êàê numpy
raw_restore = (raw_np * STD + MEAN) * 255.0
raw_uint8 = raw_restore.clip(0, 255).astype(np.uint8)

tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw_uint8)


Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py", line 103, in <module>
    raw_np = raw[0, 0].numpy()
             ^^^^^^^^^^^^^^^
AttributeError: 'numpy.ndarray' object has no attribute 'numpy'. Did you mean: 'dump'?


raw_np = raw[0, 0].numpy()
raw_restore = (raw_np * STD + MEAN) * 255.0
raw_uint8 = raw_restore.clip(0, 255).astype(np.uint8)

tifffile.imwrite(os.path.join(SAVE_DIR, f"raw_patch{i}.tif"), raw_uint8)


tifffile.imwrite(f"debug_prob_z_aff_patch{i}.tif", pred[0].astype(np.float32))  # ‰∏çÂä†ÈòàÂÄº

/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py 
yes
[Patch 0] pred max: 0.8588, mean: 0.7427, loss: 0.3448
z_aff ratio: 0.9687
y_aff ratio: 0.9969
x_aff ratio: 0.9969
[Patch 1] pred max: 0.8579, mean: 0.7712, loss: 0.2875
z_aff ratio: 0.9688
y_aff ratio: 0.9969
x_aff ratio: 0.9969
[Patch 2] pred max: 0.8536, mean: 0.7607, loss: 0.3134
z_aff ratio: 0.9688
y_aff ratio: 0.9969
x_aff ratio: 0.9969
[Patch 3] pred max: 0.8539, mean: 0.7624, loss: 0.3038
z_aff ratio: 0.9688
y_aff ratio: 0.9969
x_aff ratio: 0.9969
[Patch 4] pred max: 0.8589, mean: 0.7507, loss: 0.3274
z_aff ratio: 0.9687
y_aff ratio: 0.9969
x_aff ratio: 0.9969
[Patch 5] pred max: 0.8572, mean: 0.7525, loss: 0.3254
z_aff ratio: 0.9688
y_aff ratio: 0.9969
x_aff ratio: 0.9969
‚úÖ Saved 6 instance segmentations, raw patches, and GT patches to ./results_affinity3d
‚úÖ Average test loss: 0.3171

Process finished with exit code 0


/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py 
yes
/home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
z_aff ratio: 0.9687
y_aff ratio: 0.9969
x_aff ratio: 0.9969
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py", line 86, in <module>
    aff_mask[:-1] &= z_aff[:-1]      # z+
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'bitwise_and' output from dtype('uint8') to dtype('bool') with casting rule 'same_kind'

Process finished with exit code 1


/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py 
yes
[Patch 0] pred max: 0.8751, mean: 0.7398, loss: 0.3473
z_aff ratio: 0.0000
y_aff ratio: 0.6068
x_aff ratio: 0.9967
[Patch 1] pred max: 0.8799, mean: 0.7769, loss: 0.2806
z_aff ratio: 0.0000
y_aff ratio: 0.9966
x_aff ratio: 0.9969
[Patch 2] pred max: 0.8686, mean: 0.7608, loss: 0.3129
z_aff ratio: 0.0000
y_aff ratio: 0.9967
x_aff ratio: 0.9969
[Patch 3] pred max: 0.8813, mean: 0.7688, loss: 0.2952
z_aff ratio: 0.0000
y_aff ratio: 0.9965
x_aff ratio: 0.9969
[Patch 4] pred max: 0.8723, mean: 0.7482, loss: 0.3293
z_aff ratio: 0.0000
y_aff ratio: 0.7090
x_aff ratio: 0.9862
[Patch 5] pred max: 0.8553, mean: 0.7539, loss: 0.3240
z_aff ratio: 0.0000
y_aff ratio: 0.9944
x_aff ratio: 0.9969
‚úÖ Saved 6 instance segmentations, raw patches, and GT patches to ./results_affinity3d
‚úÖ Average test loss: 0.3149


print(f"z_aff ratio: {z_aff.sum() / z_aff.size:.4f}")
print(f"y_aff ratio: {y_aff.sum() / y_aff.size:.4f}")
print(f"x_aff ratio: {x_aff.sum() / x_aff.size:.4f}")


/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py 
yes
[Patch 0] pred max: 0.8547, mean: 0.7405, loss: 0.3469
[Patch 1] pred max: 0.8465, mean: 0.7675, loss: 0.2922
[Patch 2] pred max: 0.8497, mean: 0.7591, loss: 0.3150
[Patch 3] pred max: 0.8496, mean: 0.7603, loss: 0.3057
[Patch 4] pred max: 0.8570, mean: 0.7489, loss: 0.3294
[Patch 5] pred max: 0.8557, mean: 0.7507, loss: 0.3274
‚úÖ Saved 6 instance segmentations, raw patches, and GT patches to ./results_affinity3d
‚úÖ Average test loss: 0.3194

Process finished with exit code 0



/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py 
yes
[Patch 0] pred max: 0.8547, mean: 0.7404, loss: 0.3470
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py", line 77, in <module>
    tifffile.imwrite(os.path.join(SAVE_DIR, f"debug_z_aff_patch{i}.tif"), z_aff)
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/tifffile/tifffile.py", line 1415, in imwrite
    with TiffWriter(
         ^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/tifffile/tifffile.py", line 1743, in __init__
    self._fh = FileHandle(file, mode=mode, size=0)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/tifffile/tifffile.py", line 14695, in __init__
    self.open()
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/tifffile/tifffile.py", line 14714, in open
    self._fh = open(self._file, self._mode, encoding=None)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/guilin/PycharmProjects/MAE3d/results_affinity3d/debug_z_aff_patch0.tif'


/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py 
yes
/home/guilin/PycharmProjects/MAE3d/inference_affinity_3d.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))


import sys; print('Python %s on %s' % (sys.version, sys.platform))
/home/guilin/miniconda3/envs/pt12/bin/python -X pycache_prefix=/home/guilin/.cache/JetBrains/PyCharmCE2024.3/cpython-cache /snap/pycharm-community/465/plugins/python-ce/helpers/pydev/pydevd.py --multiprocess --qt-support=auto --client 127.0.0.1 --port 32957 --file /home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py 
Connected to pydev debugger (build 243.26053.29)
yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
[DEBUG] Input shape: torch.Size([2, 1, 32, 320, 320])
[DEBUG] Config image_size: (32, 320, 320), patch_size: [16, 16, 16]
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
[DEBUG] Patch grid D√óH√óW = 2√ó20√ó20 ‚Üí expected patches: 800, got: 800
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/snap/pycharm-community/465/plugins/python-ce/helpers/pydev/pydevd.py", line 1570, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/snap/pycharm-community/465/plugins/python-ce/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 88, in <module>
    loss = criterion(outputs, targets)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 36, in forward
    bce_loss = self.bce(input, target)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/loss.py", line 819, in forward
    return F.binary_cross_entropy_with_logits(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/functional.py", line 3624, in binary_cross_entropy_with_logits
    raise ValueError(
ValueError: Target size (torch.Size([2, 3, 32, 320, 320])) must be the same as input size (torch.Size([2, 3, 8, 80, 80]))
python-BaseException




yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]crop shape: crop shape: (32, 320, 320)(32, 320, 320)

crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
[DEBUG] Input shape: torch.Size([2, 1, 32, 320, 320])
[DEBUG] Config image_size: [32, 320, 320], patch_size: [16, 16, 16]
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
[DEBUG] Patch grid D√óH√óW = 2√ó20√ó20 ‚Üí expected patches: 800, got: 200
‚ö†Ô∏è Position embeddings mismatched ‚Äî reinitializing...
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 85, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 64, in forward
    raise ValueError(f"Mismatch: input patch count {N} does not match expected {D*H*W} from image_size {self.config.image_size} and patch_size {self.patch_size}")
ValueError: Mismatch: input patch count 200 does not match expected 800 from image_size [32, 320, 320] and patch_size [16, 16, 16]

Process finished with exit code 1




/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py 
yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
[DEBUG] Input shape: torch.Size([2, 1, 32, 320, 320])
[DEBUG] Config image_size: [32, 320, 320], patch_size: [16, 16, 16]
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
[DEBUG] Patch grid D√óH√óW = 2√ó20√ó20 ‚Üí expected patches: 800, got: 200
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 85, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 57, in forward
    raise ValueError(f"Mismatch: input patch count {N} does not match expected {D*H*W} from image_size {self.config.image_size} and patch_size {self.patch_size}")
ValueError: Mismatch: input patch count 200 does not match expected 800 from image_size [32, 320, 320] and patch_size [16, 16, 16]

Process finished with exit code 1




/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py 
yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]crop shape: (32, 320, 320)
crop shape:crop shape:  (32, 320, 320)(32, 320, 320)

crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
crop shape: (32, 320, 320)
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 85, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 51, in forward
    assert D * H * W == N, f"Mismatch: got {N} patches but expected {D}x{H}x{W}"
           ^^^^^^^^^^^^^^
AssertionError: Mismatch: got 200 patches but expected 2x20x20

Process finished with exit code 1




/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py 
yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 85, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 51, in forward
    assert D * H * W == N, f"Mismatch: got {N} patches but expected {D}x{H}x{W}"
           ^^^^^^^^^^^^^^
AssertionError: Mismatch: got 200 patches but expected 2x20x20

Process finished with exit code 1




Êä•ÈîôÔºö/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py 
yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_affinity_3d.py", line 85, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 51, in forward
    assert D * H * W == N, f"Mismatch: got {N} patches but expected {D}x{H}x{W}"
           ^^^^^^^^^^^^^^
AssertionError: Mismatch: got 200 patches but expected 2x20x20

# train_affinity_3d.pyÔºö
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, random_split
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from cremi_affinity_3d_dataset import CREMIAffinity3DDataset
from mae3d_unet_finetune import MAEUNet2Segmentation
from transformers import ViTMAEConfig

# === Config ===
H5_PATHS = [
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_A_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_B_20160501.hdf",
    "/home/guilin/PycharmProjects/MAE3d/segementation_data/sample_C_20160501.hdf",
]
CHECKPOINT = "/home/guilin/PycharmProjects/MAE3d/output/vitmae3d"
CROP_SIZE = (32, 320, 320)
BATCH_SIZE = 2
NUM_EPOCHS = 100
NUM_CLASSES = 3  # z+, y+, x+ affinity
LR = 1e-4
LOG_DIR = "./logs_affinity3d"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === Focal Loss ===
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0):
        super().__init__()
        self.gamma = gamma
        self.bce = nn.BCEWithLogitsLoss(reduction='none')

    def forward(self, input, target):
        bce_loss = self.bce(input, target)
        prob = torch.sigmoid(input)
        focal_weight = (1 - prob) ** self.gamma * target + prob ** self.gamma * (1 - target)
        return (focal_weight * bce_loss).mean()

# === Dataset ===
dataset_a = CREMIAffinity3DDataset(H5_PATHS[0], crop_size=CROP_SIZE)
dataset_b = CREMIAffinity3DDataset(H5_PATHS[1], crop_size=CROP_SIZE)
dataset_c = CREMIAffinity3DDataset(H5_PATHS[2], crop_size=CROP_SIZE)

val_ratio = 0.1
val_size = int(len(dataset_c) * val_ratio)
train_size = len(dataset_c) - val_size
train_c, val_c = random_split(dataset_c, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_dataset = ConcatDataset([dataset_a, dataset_b, train_c])
val_dataset = val_c

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# === Model ===
config = ViTMAEConfig.from_pretrained(CHECKPOINT)
model = MAEUNet2Segmentation(CHECKPOINT, config, num_classes=NUM_CLASSES).to(DEVICE)

# === Optimizer, Scheduler, Loss ===
optimizer = optim.AdamW(model.parameters(), lr=LR)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)
criterion = FocalLoss(gamma=2.0)

# === Logging ===
writer = SummaryWriter(LOG_DIR)

# === Accuracy Metric ===
def affinity_accuracy(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    correct = (preds == targets).float().mean()
    return correct.item()

# === Training Loop ===
for epoch in range(NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, targets in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Train]"):
        inputs = inputs.to(DEVICE)
        targets = targets.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    writer.add_scalar("Loss/train", avg_train_loss, epoch)

    # === Validation ===
    model.eval()
    val_loss = 0.0
    val_acc = 0.0
    with torch.no_grad():
        for inputs, targets in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Val]"):
            inputs = inputs.to(DEVICE)
            targets = targets.to(DEVICE)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            val_loss += loss.item()
            val_acc += affinity_accuracy(outputs, targets)

    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    writer.add_scalar("Loss/val", avg_val_loss, epoch)
    writer.add_scalar("Metric/AffinityAcc", avg_val_acc, epoch)
    writer.add_scalar("LR", scheduler.get_last_lr()[0], epoch)
    print(f"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, AffinityAcc: {avg_val_acc:.4f}")

    scheduler.step()

    if (epoch + 1) % 10 == 0:
        os.makedirs("./checkpoints_affinity3d", exist_ok=True)
        torch.save(model.state_dict(), f"./checkpoints_affinity3d/mae3d_unet_epoch{epoch+1}.pth")

writer.close()

# mae3d_unet_finetune.pyÔºö
import torch
import torch.nn as nn
import torch.nn.functional as F
from vitmae3d import ViTMAEForPreTraining

class MAEUNet2Decoder(nn.Module):
    def __init__(self, encoder_dim, num_classes):
        super().__init__()
        self.up1 = nn.ConvTranspose3d(encoder_dim, 128, kernel_size=2, stride=2)
        self.conv1 = nn.Sequential(
            nn.Conv3d(128, 128, 3, padding=1), nn.ReLU(),
            nn.Conv3d(128, 128, 3, padding=1), nn.ReLU()
        )
        self.up2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)
        self.conv2 = nn.Sequential(
            nn.Conv3d(64, 64, 3, padding=1), nn.ReLU(),
            nn.Conv3d(64, 64, 3, padding=1), nn.ReLU()
        )
        self.out = nn.Conv3d(64, num_classes, 1)

    def forward(self, x):
        x = self.up1(x)
        x = self.conv1(x)
        x = self.up2(x)
        x = self.conv2(x)
        return self.out(x)

class MAEUNet2Segmentation(nn.Module):
    def __init__(self, pretrained_path, config, num_classes=2):
        super().__init__()
        self.mae = ViTMAEForPreTraining.from_pretrained(pretrained_path, config=config)
        self.encoder = self.mae.vit

        self.patch_size = config.patch_size
        self.hidden_dim = config.hidden_size
        self.decoder = MAEUNet2Decoder(encoder_dim=self.hidden_dim, num_classes=num_classes)
        self.config = config

    def forward(self, x):  # x: [B, 1, D, H, W]
        B = x.shape[0]
        features = self.encoder(pixel_values=x).last_hidden_state  # [B, N+1, C]
        features = features[:, 1:, :]  # [B, N, C]

        N = features.shape[1]  # num_patches = D*H*W
        Pd, Ph, Pw = self.patch_size
        D = self.config.image_size[0] // Pd
        H = self.config.image_size[1] // Ph
        W = self.config.image_size[2] // Pw

        assert D * H * W == N, f"Mismatch: got {N} patches but expected {D}x{H}x{W}"

        x = features.transpose(1, 2).reshape(B, self.hidden_dim, D, H, W)
        return self.decoder(x)

# cremi_affinity_3d_dataset.pyÔºö
import h5py
import torch
import numpy as np
from torch.utils.data import Dataset
import random

class CREMIAffinity3DDataset(Dataset):
    def __init__(self, h5_path, raw_key="volumes/raw", label_key="volumes/labels/neuron_ids",
                 crop_size=(32, 320, 320), mean=127.91 / 255, std=28 / 255):
        super().__init__()
        self.h5_path = h5_path
        self.raw_key = raw_key
        self.label_key = label_key
        self.crop_size = crop_size
        self.mean = mean
        self.std = std

        with h5py.File(h5_path, "r") as f:
            self.raw = f[raw_key][()]
            self.labels = f[label_key][()]

        assert self.raw.shape == self.labels.shape, "Raw and label volume must have same shape"
        self.D, self.H, self.W = self.raw.shape

    def __len__(self):
        return 10000  # number of random crops per epoch

    def compute_affinities(self, ids):
        affinities = np.zeros((3, *ids.shape), dtype=np.uint8)
        affinities[0, :-1] = (ids[1:] == ids[:-1])     # z+
        affinities[1, :, :-1] = (ids[:, 1:] == ids[:, :-1])  # y+
        affinities[2, :, :, :-1] = (ids[:, :, 1:] == ids[:, :, :-1])  # x+
        return affinities

    def __getitem__(self, idx):
        zd, yh, xw = self.crop_size
        z = random.randint(0, self.D - zd)
        y = random.randint(0, self.H - yh)
        x = random.randint(0, self.W - xw)

        raw_crop = self.raw[z:z+zd, y:y+yh, x:x+xw].astype(np.float32)
        label_crop = self.labels[z:z+zd, y:y+yh, x:x+xw].astype(np.int64)

        # ÂΩí‰∏ÄÂåñ + Ê†áÂáÜÂåñ
        raw_crop = (raw_crop / 255.0 - self.mean) / self.std
        affinity = self.compute_affinities(label_crop)

        raw_tensor = torch.from_numpy(raw_crop).unsqueeze(0)  # [1, D, H, W]
        aff_tensor = torch.from_numpy(affinity.astype(np.float32))  # [3, D, H, W]
        return raw_tensor, aff_tensor



/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_segmentation.py 
yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_segmentation.py", line 85, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 51, in forward
    assert D * H * W == N, f"Mismatch: got {N} patches but expected {D}x{H}x{W}"
           ^^^^^^^^^^^^^^
AssertionError: Mismatch: got 200 patches but expected 2x20x20

Process finished with exit code 1


/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_segmentation.py 
yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_segmentation.py", line 85, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 48, in forward
    x = x.reshape(B, self.hidden_dim, *self.grid_size)  # [B, C, D, H, W]
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[2, 768, 2, 20, 20]' is invalid for input of size 307200



/home/guilin/miniconda3/envs/pt12/bin/python /home/guilin/PycharmProjects/MAE3d/train_segmentation.py 
yes
Epoch 1/100 [Train]:   0%|          | 0/14500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/train_segmentation.py", line 85, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/mae3d_unet_finetune.py", line 45, in forward
    features = self.encoder(pixel_values=x).last_hidden_state  # [B, N+1, C]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 823, in forward
    embedding_output, mask, ids_restore = self.embeddings(
                                          ^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 322, in forward
    embeddings = embeddings + position_embeddings[:, 1:, :]
                 ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
RuntimeError: The size of tensor a (200) must match the size of tensor b (800) at non-singleton dimension 1




final_reconstruction[mask_cpu] = reconstructed[mask_cpu]
                                     ~~~~~~~~~~~~~^^^^^^^^^^
IndexError: boolean index did not match indexed array along dimension 0; dimension is 32 but corresponding boolean dimension is 800
(pt12) guilin@guilin-System-Product-Name:~/PycharmProjects/MAE3d$ python inference.py
Loading model from: /home/guilin/PycharmProjects/MAE3d/output/vitmae3d/checkpoint-1780000
yes
Reconstruction loss: 0.4297
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference.py", line 63, in <module>
    final_reconstruction[mask_cpu] = reconstructed[mask_cpu]
                                     ~~~~~~~~~~~~~^^^^^^^^^^
IndexError: boolean index did not match indexed array along dimension 0; dimension is 32 but corresponding boolean dimension is 800




(pt12) guilin@guilin-System-Product-Name:~/PycharmProjects/MAE3d$ python inference.py
Loading model from: /home/guilin/PycharmProjects/MAE3d/output/vitmae3d/checkpoint-1670000
yes
Reconstruction loss: 0.4615
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference.py", line 58, in <module>
    masked_volume = model.unpatchify(masked_patchified)[0, 0].cpu().numpy() * STD + MEAN
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1129, in unpatchify
    patchified_pixel_values = torch.einsum("ndhwpqc->ncdhwpq", patchified_pixel_values)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: einsum(): the number of subscripts in the equation (7) does not match the number of dimensions (8) for operand 0 and no ellipsis was given


(pt12) guilin@guilin-System-Product-Name:~/PycharmProjects/MAE3d$ python inference.py
Loading model from: /home/guilin/PycharmProjects/MAE3d/output/vitmae3d/checkpoint-1670000
yes
Reconstruction loss: 0.4652
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference.py", line 58, in <module>
    masked_volume = model.unpatchify(masked_patchified)[0, 0].cpu().numpy() * STD + MEAN
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1112, in unpatchify
    num_patches_d = original_depth // pd
                    ~~~~~~~~~~~~~~~^^~~~
TypeError: unsupported operand type(s) for //: 'tuple' and 'int'



(pt12) guilin@guilin-System-Product-Name:~/PycharmProjects/MAE3d$ python inference.py
Loading model from: /home/guilin/PycharmProjects/MAE3d/output/vitmae3d/checkpoint-50000
yes
Reconstruction loss: 0.6117
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference.py", line 57, in <module>
    masked_volume = model.unpatchify(masked_patchified)[0, 0].cpu().numpy() * STD + MEAN
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1112, in unpatchify
    num_patches_d = original_depth // pd
                    ~~~~~~~~~~~~~~~^^~~~
TypeError: unsupported operand type(s) for //: 'list' and 'int'



(pt12) guilin@guilin-System-Product-Name:~/PycharmProjects/MAE3d$ python inference.py
Loading model from: /home/guilin/PycharmProjects/MAE3d/output/vitmae3d/checkpoint-50000
yes
Reconstruction loss: 0.6272
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/inference.py", line 53, in <module>
    masked_patchified[0][mask.bool()] = 0  # Â∞ÜË¢´ mask ÁöÑ patch ÁΩÆ‰∏∫ 0
    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
IndexError: The shape of the mask [1, 800] at index 0 does not match the shape of the indexed tensor [800, 4096] at index 0


Traceback (most recent call last):                                                                                                                                                                                         
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 3162, in _determine_best_metric
    metric_value = metrics[metric_to_check]
                   ~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'eval_accuracy'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 225, in <module>
    main()
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 216, in main
    trainer.train()
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 2620, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 3094, in _maybe_log_save_evaluate
    is_new_best_metric = self._determine_best_metric(metrics=metrics, trial=trial)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 3164, in _determine_best_metric
    raise KeyError(
KeyError: "The `metric_for_best_model` training argument is set to 'eval_accuracy', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch']. Consider changing the `metric_for_best_model` via the TrainingArguments."




Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 225, in <module>
    main()
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 197, in main
    f.write(f"{name:60s} | shape: {tuple(param.shape):20s} | requires_grad={param.requires_grad}\n")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: unsupported format string passed to tuple.__format__


warnings.warn(
Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 225, in <module>
    main()
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 133, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/hf_argparser.py", line 358, in parse_args_into_dataclasses
    obj = dtype(**inputs)
          ^^^^^^^^^^^^^^^
  File "<string>", line 136, in __init__
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/training_args.py", line 1678, in __post_init__
    raise ValueError(
ValueError: --load_best_model_at_end requires the save and eval strategy to match, but found
- Evaluation strategy: IntervalStrategy.STEPS
- Save strategy: SaveStrategy.EPOCH


tensorboard --logdir ./output_dir/tb_samples


AssertionError: size of input tensor and input format are different.         tensor shape: (1, 320), input_format: CHW



0%|                                                                                                                                                                            | 499/4176700 [01:03<148:04:00,  7.83it/s](pt12) guilin@guilin-System-Product-Name:~/data_proccess$ python unzip.py ./EM_pretrain_data
Extracting FAFB_crop_hdf_4.zip to ./EM_pretrain_data/FAFB_crop_hdf_4...
Extracting Kasthuri2015_hdf_5.zip to ./EM_pretrain_data/Kasthuri2015_hdf_5...
Extracting Kasthuri2015_hdf_9.zip to ./EM_pretrain_data/Kasthuri2015_hdf_9...
Extracting Kasthuri2015_hdf_8.zip to ./EM_pretrain_data/Kasthuri2015_hdf_8...
Extracting Kasthuri2015_hdf_2.zip to ./EM_pretrain_data/Kasthuri2015_hdf_2...
Extracting FIB-25_hdf_6.zip to ./EM_pretrain_data/FIB-25_hdf_6...
Extracting Kasthuri2015_hdf_3.zip to ./EM_pretrain_data/Kasthuri2015_hdf_3...
Traceback (most recent call last):
  File "/home/guilin/data_proccess/unzip.py", line 52, in <module>
    extract_all_in_dir(args.dir)
  File "/home/guilin/data_proccess/unzip.py", line 44, in extract_all_in_dir
    extract_archive(fpath, out_dir)
  File "/home/guilin/data_proccess/unzip.py", line 9, in extract_archive
    with zipfile.ZipFile(archive_path, 'r') as zip_ref:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/zipfile/__init__.py", line 1349, in __init__
    self._RealGetContents()
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/zipfile/__init__.py", line 1416, in _RealGetContents
    raise BadZipFile("File is not a zip file")
zipfile.BadZipFile: File is not a zip file



FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
INFO:__main__:Loading data...
yes
INFO:__main__:Start training...
{'loss': 0.9422, 'grad_norm': 0.2779630422592163, 'learning_rate': 3.906246120865152e-06, 'epoch': 0.0}                                                                                                                    
{'eval_runtime': 380.9952, 'eval_samples_per_second': 29.368, 'eval_steps_per_second': 29.368, 'epoch': 0.0}                                                                                                               
{'loss': 0.9468, 'grad_norm': 0.21853122115135193, 'learning_rate': 3.906242241730305e-06, 'epoch': 0.0}                                                                                                                   
{'eval_runtime': 388.9377, 'eval_samples_per_second': 28.768, 'eval_steps_per_second': 28.768, 'epoch': 0.0}                                                                                                               
{'loss': 1.018, 'grad_norm': 0.20022796094417572, 'learning_rate': 3.906238362595458e-06, 'epoch': 0.0}                                                                                                                    
  0%|                                                                                                                                                                          | 30/10069900 [13:10<51206:24:19, 18.31s/it]
 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                                                                 | 4037/11189 [02:15<04:14, 28.07it/s]



FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
INFO:__main__:Loading data...
yes
INFO:__main__:Start training...
  0%|                                                                                                                                                                                         | 0/10069900 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 144, in <module>
    main()
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 135, in main
    trainer.train()
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 2556, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 3718, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 3783, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1216, in forward
    loss = self.forward_loss(pixel_values, logits, mask, interpolate_pos_encoding=interpolate_pos_encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1152, in forward_loss
    target = self.patchify(pixel_values, interpolate_pos_encoding=interpolate_pos_encoding)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1084, in patchify
    patchified_pixel_values = torch.einsum("ncdhwpq->ndhwpqc", patchified_pixel_values)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: einsum(): the number of subscripts in the equation (7) does not match the number of dimensions (8) for operand 0 and no ellipsis was given
  0%| 
