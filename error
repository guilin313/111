(pt12) guilin@guilin-System-Product-Name:~/data_proccess$ python unzip.py ./EM_pretrain_data
Extracting FAFB_crop_hdf_4.zip to ./EM_pretrain_data/FAFB_crop_hdf_4...
Extracting Kasthuri2015_hdf_5.zip to ./EM_pretrain_data/Kasthuri2015_hdf_5...
Extracting Kasthuri2015_hdf_9.zip to ./EM_pretrain_data/Kasthuri2015_hdf_9...
Extracting Kasthuri2015_hdf_8.zip to ./EM_pretrain_data/Kasthuri2015_hdf_8...
Extracting Kasthuri2015_hdf_2.zip to ./EM_pretrain_data/Kasthuri2015_hdf_2...
Extracting FIB-25_hdf_6.zip to ./EM_pretrain_data/FIB-25_hdf_6...
Extracting Kasthuri2015_hdf_3.zip to ./EM_pretrain_data/Kasthuri2015_hdf_3...
Traceback (most recent call last):
  File "/home/guilin/data_proccess/unzip.py", line 52, in <module>
    extract_all_in_dir(args.dir)
  File "/home/guilin/data_proccess/unzip.py", line 44, in extract_all_in_dir
    extract_archive(fpath, out_dir)
  File "/home/guilin/data_proccess/unzip.py", line 9, in extract_archive
    with zipfile.ZipFile(archive_path, 'r') as zip_ref:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/zipfile/__init__.py", line 1349, in __init__
    self._RealGetContents()
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/zipfile/__init__.py", line 1416, in _RealGetContents
    raise BadZipFile("File is not a zip file")
zipfile.BadZipFile: File is not a zip file



FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
INFO:__main__:Loading data...
yes
INFO:__main__:Start training...
{'loss': 0.9422, 'grad_norm': 0.2779630422592163, 'learning_rate': 3.906246120865152e-06, 'epoch': 0.0}                                                                                                                    
{'eval_runtime': 380.9952, 'eval_samples_per_second': 29.368, 'eval_steps_per_second': 29.368, 'epoch': 0.0}                                                                                                               
{'loss': 0.9468, 'grad_norm': 0.21853122115135193, 'learning_rate': 3.906242241730305e-06, 'epoch': 0.0}                                                                                                                   
{'eval_runtime': 388.9377, 'eval_samples_per_second': 28.768, 'eval_steps_per_second': 28.768, 'epoch': 0.0}                                                                                                               
{'loss': 1.018, 'grad_norm': 0.20022796094417572, 'learning_rate': 3.906238362595458e-06, 'epoch': 0.0}                                                                                                                    
  0%|                                                                                                                                                                          | 30/10069900 [13:10<51206:24:19, 18.31s/it]
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                 | 4037/11189 [02:15<04:14, 28.07it/s]



FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
INFO:__main__:Loading data...
yes
INFO:__main__:Start training...
  0%|                                                                                                                                                                                         | 0/10069900 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 144, in <module>
    main()
  File "/home/guilin/PycharmProjects/MAE3d/run_mae_3d.py", line 135, in main
    trainer.train()
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 2556, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 3718, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/transformers/trainer.py", line 3783, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1216, in forward
    loss = self.forward_loss(pixel_values, logits, mask, interpolate_pos_encoding=interpolate_pos_encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1152, in forward_loss
    target = self.patchify(pixel_values, interpolate_pos_encoding=interpolate_pos_encoding)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/PycharmProjects/MAE3d/vitmae3d.py", line 1084, in patchify
    patchified_pixel_values = torch.einsum("ncdhwpq->ndhwpqc", patchified_pixel_values)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/guilin/miniconda3/envs/pt12/lib/python3.12/site-packages/torch/functional.py", line 402, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: einsum(): the number of subscripts in the equation (7) does not match the number of dimensions (8) for operand 0 and no ellipsis was given
  0%| 
